2025-07-13 23:48:06 [INFO] pipeline - Ingestão: iniciando leitura de data/raw/vendas.csv
2025-07-13 23:48:06 [INFO] pipeline - Ingestão: lido DataFrame com shape (135226, 3)
2025-07-13 23:48:06 [INFO] pipeline - Ingestão: colunas renomeadas para ['sku', 'data', 'vendas']
2025-07-13 23:48:06 [INFO] pipeline - Ingestão: dados salvos em Delta Lake: data/interim/vendas_interim.delta
2025-07-13 23:48:06 [INFO] pipeline - Ingestão: término da ingestão e armazenamento de versões.
2025-07-13 23:48:06 [INFO] pipeline - Ingestão finalizada com sucesso.
2025-07-13 23:48:14 [INFO] pipeline - Agregação: Iniciando agregação macro de vendas
2025-07-13 23:48:14 [INFO] pipeline - Agregação: Lendo Delta de entrada em data/interim/vendas_interim.delta
2025-07-13 23:48:14 [INFO] pipeline - Agregação: Dados carregados: 135226 linhas
2025-07-13 23:48:14 [INFO] pipeline - Agregação: Cálculo de vendas_total concluído
2025-07-13 23:48:14 [INFO] pipeline - Agregação: Cálculo de SKUs vendidos concluído (total SKUs=5696)
2025-07-13 23:48:14 [INFO] pipeline - Agregação: Merge dos dados agregados concluído: 86 linhas
2025-07-13 23:48:14 [INFO] pipeline - Agregação: CSV agregado salvo em data/interim/aggregated_sales.csv
2025-07-13 23:48:14 [INFO] pipeline - Agregação: Diretório Delta anterior removido: data/interim/aggregated_sales.delta
2025-07-13 23:48:14 [INFO] pipeline - Agregação: Delta agregado salvo em data/interim/aggregated_sales.delta
2025-07-13 23:48:14 [INFO] pipeline - Agregação macro concluída com sucesso
2025-07-13 23:48:22 [INFO] pipeline - Processado: lendo Delta em data/interim/vendas_interim.delta
2025-07-13 23:48:22 [INFO] pipeline - Processado: DataFrame carregado com shape (135226, 3)
2025-07-13 23:48:22 [INFO] pipeline - Processado: início clean_data com df.shape=(135226, 3)
2025-07-13 23:48:22 [INFO] pipeline - Processado: datetime aplicado em 'data'.
2025-07-13 23:48:22 [INFO] pipeline - Processado: expandido para df_full.shape=(489856, 3)
2025-07-13 23:48:24 [INFO] pipeline - Processado: marcado is_imputed, total imputados=354630
2025-07-13 23:48:24 [INFO] pipeline - ✔ Clean completo: 489856 linhas salvas em data/processed/vendas_processed.csv
2025-07-13 23:48:24 [INFO] pipeline - ✔ Clean Delta completo: 489856 linhas salvas em data/processed/vendas_processed.delta
2025-07-13 23:48:31 [INFO] pipeline - Features: lendo Delta de data/processed/vendas_processed.delta
2025-07-13 23:48:32 [INFO] pipeline - Features: DataFrame carregado com shape (489856, 4)
2025-07-13 23:48:34 [INFO] pipeline - Features: features geradas; df_feats.shape=(489856, 14)
2025-07-13 23:48:35 [INFO] pipeline - ✔ CSV de features salvo em data/features/vendas_features.csv
2025-07-13 23:48:36 [INFO] pipeline - ✔ Delta de features salvo em data/features/vendas_features.delta
2025-07-13 23:49:02 [INFO] pipeline - SARIMA: Iniciando SARIMA order=(1, 1, 1) seasonal=(1, 1, 1, 7)
2025-07-13 23:49:02 [INFO] pipeline - SARIMA ajustado com sucesso
2025-07-13 23:49:02 [INFO] pipeline - SARIMAForecast gerado para o período 2024-04-09 até 2024-04-15
2025-07-13 23:49:02 [INFO] pipeline - SARIMA salvo em models/sarima_model.pkl
2025-07-13 23:49:02 [INFO] pipeline - Treinando LightGBM com {'objective': 'regression', 'metric': 'rmse'}
2025-07-13 23:49:05 [INFO] pipeline - LightGBM metrics: {'rmse': 6.321117964186915, 'mae': 1.6013831674023828, 'mape': np.float64(7.002794253756646), 'r2': 0.9550409671974993, 'wmape': np.float64(20.124671309551935)}
2025-07-13 23:49:05 [INFO] pipeline - LightGBM salvo em models/lgb_model.pkl
2025-07-13 23:49:05 [INFO] pipeline - Treinando CatBoost com {'verbose': 0}
2025-07-13 23:49:29 [INFO] pipeline - CatBoost metrics: {'rmse': 6.193205056994577, 'mae': 1.7003662737630383, 'mape': np.float64(15.847823653347906), 'r2': 0.956842121417274, 'wmape': np.float64(21.36859751113544)}
2025-07-13 23:49:29 [INFO] pipeline - CatBoost salvo em models/catboost_model.cbm
2025-07-13 23:49:29 [INFO] pipeline - Orquestração de treinamento finalizada.
2025-07-13 23:51:54 [INFO] pipeline - SARIMA: Iniciando SARIMA order=(1, 1, 1) seasonal=(1, 1, 1, 7)
2025-07-13 23:51:54 [INFO] pipeline - SARIMA ajustado com sucesso
2025-07-13 23:51:54 [INFO] pipeline - SARIMA: Forecast gerado para o período 2024-04-09 até 2024-04-15
2025-07-13 23:51:54 [INFO] pipeline - SARIMA salvo em models/sarima_model.pkl
2025-07-13 23:51:55 [INFO] pipeline - Treinando LightGBM com {'objective': 'regression', 'metric': 'rmse'}
2025-07-13 23:51:56 [INFO] pipeline - LightGBM metrics: {'rmse': 6.321117964186915, 'mae': 1.6013831674023828, 'mape': np.float64(7.002794253756646), 'r2': 0.9550409671974993, 'wmape': np.float64(20.124671309551935)}
2025-07-13 23:51:56 [INFO] pipeline - LightGBM salvo em models/lgb_model.pkl
2025-07-13 23:51:56 [INFO] pipeline - Treinando CatBoost com {'verbose': 0}
2025-07-13 23:52:21 [INFO] pipeline - CatBoost metrics: {'rmse': 6.193205056994577, 'mae': 1.7003662737630383, 'mape': np.float64(15.847823653347906), 'r2': 0.956842121417274, 'wmape': np.float64(21.36859751113544)}
2025-07-13 23:52:21 [INFO] pipeline - CatBoost salvo em models/catboost_model.cbm
2025-07-13 23:52:21 [INFO] pipeline - Orquestração de treinamento finalizada.
2025-07-14 08:29:33 [INFO] pipeline - SARIMA: Iniciando order=(1, 1, 1) seasonal=(1, 1, 1, 7)
2025-07-14 08:29:33 [INFO] pipeline - Série com frequência definida como <Day>
2025-07-14 08:29:33 [INFO] pipeline - ADF test d=0: p-value=0.0501
2025-07-14 08:29:33 [INFO] pipeline - ADF test d=1: p-value=0.0121
2025-07-14 08:29:33 [INFO] pipeline - Série final para modelagem d=1
2025-07-14 08:29:33 [INFO] pipeline - SARIMA ajustado com sucesso
2025-07-14 08:29:33 [INFO] pipeline - SARIMA metrics on historical split: {'rmse': 10263.561996229066, 'mae': 8082.068443348698, 'mape': np.float64(121.0441006339235), 'r2': 0.838303664202277, 'wmape': np.float64(1395.8667432381171)}
2025-07-14 08:29:33 [INFO] pipeline - SARIMA: Forecast gerado para o período 2024-04-09 até 2024-04-15
2025-07-14 08:29:33 [INFO] pipeline - SARIMA salvo em models/sarima_model.pkl
2025-07-14 08:29:34 [INFO] pipeline - Treinando LightGBM com {'objective': 'regression', 'metric': 'rmse'}
2025-07-14 08:29:35 [INFO] pipeline - LightGBM metrics: {'rmse': 6.321117964186915, 'mae': 1.6013831674023828, 'mape': np.float64(7.002794253756646), 'r2': 0.9550409671974993, 'wmape': np.float64(20.124671309551935)}
2025-07-14 08:29:35 [INFO] pipeline - LightGBM salvo em models/lgb_model.pkl
2025-07-14 08:29:35 [INFO] pipeline - Treinando CatBoost com {'verbose': 0}
2025-07-14 08:29:59 [INFO] pipeline - CatBoost metrics: {'rmse': 6.193205056994577, 'mae': 1.7003662737630383, 'mape': np.float64(15.847823653347906), 'r2': 0.956842121417274, 'wmape': np.float64(21.36859751113544)}
2025-07-14 08:29:59 [INFO] pipeline - CatBoost salvo em models/catboost_model.cbm
2025-07-14 08:29:59 [INFO] pipeline - Orquestração de treinamento finalizada.
2025-07-14 11:57:25 [INFO] pipeline - SARIMA: Iniciando order=(1, 1, 1) seasonal=(1, 1, 1, 7)
2025-07-14 11:57:25 [INFO] pipeline - Série com frequência definida como <Day>
2025-07-14 11:57:25 [INFO] pipeline - ADF test d=0: p-value=0.0501
2025-07-14 11:57:25 [INFO] pipeline - ADF test d=1: p-value=0.0121
2025-07-14 11:57:25 [INFO] pipeline - Série final para modelagem d=1
2025-07-14 11:57:25 [INFO] pipeline - SARIMA ajustado com sucesso
2025-07-14 11:57:25 [INFO] pipeline - SARIMA metrics on historical split: {'rmse': 10263.561996229066, 'mae': 8082.068443348698, 'mape': np.float64(121.0441006339235), 'r2': 0.838303664202277, 'wmape': np.float64(1395.8667432381171)}
2025-07-14 11:57:25 [INFO] pipeline - SARIMA: Forecast gerado para o período 2024-04-09 até 2024-04-15
2025-07-14 11:57:25 [INFO] pipeline - SARIMA salvo em models/sarima_model.pkl
2025-07-14 11:57:25 [INFO] pipeline - SARIMA forecast exportado em data/models/sarima_forecast.csv
2025-07-14 11:57:26 [INFO] pipeline - Treinando LightGBM com {'objective': 'regression', 'metric': 'rmse'}
2025-07-14 11:58:54 [INFO] pipeline - SARIMA: Iniciando order=(1, 1, 1) seasonal=(1, 1, 1, 7)
2025-07-14 11:58:54 [INFO] pipeline - Série com frequência definida como <Day>
2025-07-14 11:58:54 [INFO] pipeline - ADF test d=0: p-value=0.0501
2025-07-14 11:58:54 [INFO] pipeline - ADF test d=1: p-value=0.0121
2025-07-14 11:58:54 [INFO] pipeline - Série final para modelagem d=1
2025-07-14 11:58:54 [INFO] pipeline - SARIMA ajustado com sucesso
2025-07-14 11:58:54 [INFO] pipeline - SARIMA metrics on historical split: {'rmse': 10263.561996229066, 'mae': 8082.068443348698, 'mape': np.float64(121.0441006339235), 'r2': 0.838303664202277, 'wmape': np.float64(1395.8667432381171)}
2025-07-14 11:58:54 [INFO] pipeline - SARIMA: Forecast gerado para o período 2024-04-09 até 2024-04-15
2025-07-14 11:58:54 [INFO] pipeline - SARIMA salvo em models/sarima_model.pkl
2025-07-14 11:58:54 [INFO] pipeline - SARIMA forecast exportado em data/models/sarima_forecast.csv
2025-07-14 11:58:54 [INFO] pipeline - Treinando LightGBM com {'objective': 'regression', 'metric': 'rmse'}
2025-07-15 05:46:38 [INFO] pipeline - SARIMA: Iniciando order=(1, 1, 1) seasonal=(1, 1, 1, 7)
2025-07-15 05:46:38 [INFO] pipeline - Série com frequência definida como <Day>
2025-07-15 05:46:38 [INFO] pipeline - ADF test d=0: p-value=0.0501
2025-07-15 05:46:38 [INFO] pipeline - ADF test d=1: p-value=0.0121
2025-07-15 05:46:38 [INFO] pipeline - Série final para modelagem d=1
2025-07-15 05:46:38 [INFO] pipeline - SARIMA ajustado com sucesso
2025-07-15 05:46:38 [INFO] pipeline - SARIMA metrics on historical split: {'rmse': 10263.561996229066, 'mae': 8082.068443348698, 'mape': np.float64(121.0441006339235), 'r2': 0.838303664202277, 'wmape': np.float64(1395.8667432381171)}
2025-07-15 05:46:38 [INFO] pipeline - SARIMA: Forecast gerado para o período 2024-04-09 até 2024-04-15
2025-07-15 05:46:38 [INFO] pipeline - SARIMA salvo em models/sarima_model.pkl
2025-07-15 05:46:38 [INFO] pipeline - SARIMA forecast exportado em data/models/sarima_forecast.csv
2025-07-15 05:46:39 [INFO] pipeline - Treinando LightGBM com {'objective': 'regression', 'metric': 'rmse'}
2025-07-15 05:59:51 [INFO] pipeline - SARIMA: Iniciando order=(1, 1, 1) seasonal=(1, 1, 1, 7)
2025-07-15 05:59:51 [INFO] pipeline - Série com frequência definida como <Day>
2025-07-15 05:59:51 [INFO] pipeline - ADF test d=0: p-value=0.0501
2025-07-15 05:59:51 [INFO] pipeline - ADF test d=1: p-value=0.0121
2025-07-15 05:59:51 [INFO] pipeline - Série final para modelagem d=1
2025-07-15 05:59:51 [INFO] pipeline - SARIMA ajustado com sucesso
2025-07-15 05:59:51 [INFO] pipeline - SARIMA metrics on historical split: {'rmse': 10263.561996229066, 'mae': 8082.068443348698, 'mape': np.float64(121.0441006339235), 'r2': 0.838303664202277, 'wmape': np.float64(1395.8667432381171)}
2025-07-15 05:59:51 [INFO] pipeline - SARIMA: Forecast gerado para o período 2024-04-09 até 2024-04-15
2025-07-15 05:59:51 [INFO] pipeline - SARIMA salvo em models/sarima_model.pkl
2025-07-15 05:59:51 [INFO] pipeline - SARIMA forecast exportado em data/models/sarima_forecast.csv
2025-07-15 05:59:52 [INFO] pipeline - Treinando LightGBM com {'objective': 'regression', 'metric': 'rmse'}
2025-07-15 05:59:54 [INFO] pipeline - ML forecast exportado em data/models/ml_forecast.csv
2025-07-15 05:59:54 [INFO] pipeline - LightGBM metrics: {'rmse': 6.321117964186915, 'mae': 1.6013831674023828, 'mape': np.float64(7.002794253756646), 'r2': 0.9550409671974993, 'wmape': np.float64(20.124671309551935)}
2025-07-15 05:59:54 [INFO] pipeline - LightGBM salvo em models/lgb_model.pkl
2025-07-15 05:59:54 [INFO] pipeline - Treinando CatBoost com {'verbose': 0}
2025-07-15 06:01:10 [INFO] pipeline - SARIMA: Iniciando order=(1, 1, 1) seasonal=(1, 1, 1, 7)
2025-07-15 06:01:10 [INFO] pipeline - Série com frequência definida como <Day>
2025-07-15 06:01:10 [INFO] pipeline - ADF test d=0: p-value=0.0501
2025-07-15 06:01:10 [INFO] pipeline - ADF test d=1: p-value=0.0121
2025-07-15 06:01:10 [INFO] pipeline - Série final para modelagem d=1
2025-07-15 06:01:10 [INFO] pipeline - SARIMA ajustado com sucesso
2025-07-15 06:01:10 [INFO] pipeline - SARIMA metrics on historical split: {'rmse': 10263.561996229066, 'mae': 8082.068443348698, 'mape': np.float64(121.0441006339235), 'r2': 0.838303664202277, 'wmape': np.float64(1395.8667432381171)}
2025-07-15 06:01:10 [INFO] pipeline - SARIMA: Forecast gerado para o período 2024-04-09 até 2024-04-15
2025-07-15 06:01:10 [INFO] pipeline - SARIMA salvo em models/sarima_model.pkl
2025-07-15 06:01:10 [INFO] pipeline - SARIMA forecast exportado em data/models/sarima_forecast.csv
2025-07-15 06:01:11 [INFO] pipeline - Treinando LightGBM com {'objective': 'regression', 'metric': 'rmse'}
2025-07-15 06:01:13 [INFO] pipeline - ML forecast exportado em data/models/ml_forecast.csv
2025-07-15 06:01:13 [INFO] pipeline - LightGBM metrics: {'rmse': 6.321117964186915, 'mae': 1.6013831674023828, 'mape': np.float64(7.002794253756646), 'r2': 0.9550409671974993, 'wmape': np.float64(20.124671309551935)}
2025-07-15 06:01:13 [INFO] pipeline - LightGBM salvo em models/lgb_model.pkl
2025-07-15 06:01:13 [INFO] pipeline - Treinando CatBoost com {'verbose': 0}
2025-07-15 06:01:37 [INFO] pipeline - CatBoost forecast exportado em data/models/catboost_forecast.csv
2025-07-15 06:01:37 [INFO] pipeline - CatBoost metrics: {'rmse': 6.193205056994577, 'mae': 1.7003662737630383, 'mape': np.float64(15.847823653347906), 'r2': 0.956842121417274, 'wmape': np.float64(21.36859751113544)}
2025-07-15 06:01:37 [INFO] pipeline - CatBoost salvo em models/catboost_model.cbm
2025-07-15 06:01:37 [INFO] pipeline - Orquestração de treinamento finalizada.
2025-07-15 06:06:22 [INFO] pipeline - Ingestão: iniciando leitura de data/raw/vendas.csv
2025-07-15 06:06:22 [INFO] pipeline - Ingestão: lido DataFrame com shape (135226, 3)
2025-07-15 06:06:22 [INFO] pipeline - Ingestão: colunas renomeadas para ['sku', 'data', 'vendas']
2025-07-15 06:06:23 [INFO] pipeline - Ingestão: dados salvos em Delta Lake: data/interim/vendas_interim.delta
2025-07-15 06:06:23 [INFO] pipeline - Ingestão: término da ingestão e armazenamento de versões.
2025-07-15 06:06:23 [INFO] pipeline - Ingestão finalizada com sucesso.
2025-07-15 06:06:29 [INFO] pipeline - Processado: lendo Delta em data/interim/vendas_interim.delta
2025-07-15 06:06:29 [INFO] pipeline - Processado: DataFrame carregado com shape (135226, 3)
2025-07-15 06:06:29 [INFO] pipeline - Processado: início clean_data com df.shape=(135226, 3)
2025-07-15 06:06:29 [INFO] pipeline - Processado: datetime aplicado em 'data'.
2025-07-15 06:06:29 [INFO] pipeline - Processado: expandido para df_full.shape=(489856, 3)
2025-07-15 06:06:31 [INFO] pipeline - Processado: marcado is_imputed, total imputados=354630
2025-07-15 06:06:31 [INFO] pipeline - ✔ Clean completo: 489856 linhas salvas em data/processed/vendas_processed.csv
2025-07-15 06:06:31 [INFO] pipeline - ✔ Clean Delta completo: 489856 linhas salvas em data/processed/vendas_processed.delta
2025-07-15 06:06:38 [INFO] pipeline - Features: lendo Delta de data/processed/vendas_processed.delta
2025-07-15 06:06:38 [INFO] pipeline - Features: DataFrame carregado com shape (489856, 4)
2025-07-15 06:06:40 [INFO] pipeline - Features: features geradas; df_feats.shape=(489856, 14)
2025-07-15 06:06:42 [INFO] pipeline - ✔ CSV de features salvo em data/features/vendas_features.csv
2025-07-15 06:06:43 [INFO] pipeline - ✔ Delta de features salvo em data/features/vendas_features.delta
2025-07-15 06:07:13 [INFO] pipeline - SARIMA: Iniciando order=(1, 1, 1) seasonal=(1, 1, 1, 7)
2025-07-15 06:07:13 [INFO] pipeline - Série com frequência definida como <Day>
2025-07-15 06:07:13 [INFO] pipeline - ADF test d=0: p-value=0.0501
2025-07-15 06:07:13 [INFO] pipeline - ADF test d=1: p-value=0.0121
2025-07-15 06:07:13 [INFO] pipeline - Série final para modelagem d=1
2025-07-15 06:07:13 [INFO] pipeline - SARIMA ajustado com sucesso
2025-07-15 06:07:13 [INFO] pipeline - SARIMA metrics on historical split: {'rmse': 10263.561996229066, 'mae': 8082.068443348698, 'mape': np.float64(121.0441006339235), 'r2': 0.838303664202277, 'wmape': np.float64(1395.8667432381171)}
2025-07-15 06:07:13 [INFO] pipeline - SARIMA: Forecast gerado para o período 2024-04-09 até 2024-04-15
2025-07-15 06:07:13 [INFO] pipeline - SARIMA salvo em models/sarima_model.pkl
2025-07-15 06:07:13 [INFO] pipeline - SARIMA forecast exportado em data/models/sarima_forecast.csv
2025-07-15 06:07:13 [INFO] pipeline - Treinando LightGBM com {'objective': 'regression', 'metric': 'rmse'}
2025-07-15 06:07:16 [INFO] pipeline - ML forecast exportado em data/models/ml_forecast.csv
2025-07-15 06:07:16 [INFO] pipeline - LightGBM metrics: {'rmse': 6.321117964186915, 'mae': 1.6013831674023828, 'mape': np.float64(7.002794253756646), 'r2': 0.9550409671974993, 'wmape': np.float64(20.124671309551935)}
2025-07-15 06:07:16 [INFO] pipeline - LightGBM salvo em models/lgb_model.pkl
2025-07-15 06:07:16 [INFO] pipeline - Treinando CatBoost com {'verbose': 0}
2025-07-15 06:07:41 [INFO] pipeline - CatBoost forecast exportado em data/models/catboost_forecast.csv
2025-07-15 06:07:41 [INFO] pipeline - CatBoost metrics: {'rmse': 6.193205056994577, 'mae': 1.7003662737630383, 'mape': np.float64(15.847823653347906), 'r2': 0.956842121417274, 'wmape': np.float64(21.36859751113544)}
2025-07-15 06:07:41 [INFO] pipeline - CatBoost salvo em models/catboost_model.cbm
2025-07-15 06:07:41 [INFO] pipeline - Orquestração de treinamento finalizada.
2025-07-15 06:51:29 [INFO] pipeline - Ingestão: iniciando leitura de data/raw/vendas.csv
2025-07-15 06:51:30 [INFO] pipeline - Ingestão: lido DataFrame com shape (135226, 3)
2025-07-15 06:51:30 [INFO] pipeline - Ingestão: colunas renomeadas para ['sku', 'data', 'vendas']
2025-07-15 06:51:30 [INFO] pipeline - Ingestão: dados salvos em Delta Lake: data/interim/vendas_interim.delta
2025-07-15 06:51:30 [INFO] pipeline - Ingestão: término da ingestão e armazenamento de versões.
2025-07-15 06:51:30 [INFO] pipeline - Ingestão finalizada com sucesso.
2025-07-15 06:51:35 [INFO] pipeline - Processado: lendo Delta em data/interim/vendas_interim.delta
2025-07-15 06:51:35 [INFO] pipeline - Processado: DataFrame carregado com shape (135226, 3)
2025-07-15 06:51:35 [INFO] pipeline - Processado: início clean_data com df.shape=(135226, 3)
2025-07-15 06:51:35 [INFO] pipeline - Processado: datetime aplicado em 'data'.
2025-07-15 06:51:35 [INFO] pipeline - Processado: expandido para df_full.shape=(489856, 3)
2025-07-15 06:51:37 [INFO] pipeline - Processado: marcado is_imputed, total imputados=354630
2025-07-15 06:51:38 [INFO] pipeline - ✔ Clean completo: 489856 linhas salvas em data/processed/vendas_processed.csv
2025-07-15 06:51:38 [INFO] pipeline - ✔ Clean Delta completo: 489856 linhas salvas em data/processed/vendas_processed.delta
2025-07-15 06:51:47 [INFO] pipeline - Agregação: Iniciando agregação macro de vendas
2025-07-15 06:51:47 [INFO] pipeline - Agregação: Lendo Delta de entrada em data/interim/vendas_interim.delta
2025-07-15 06:51:47 [INFO] pipeline - Agregação: Dados carregados: 135226 linhas
2025-07-15 06:51:47 [INFO] pipeline - Agregação: Cálculo de vendas_total concluído
2025-07-15 06:51:47 [INFO] pipeline - Agregação: Cálculo de SKUs vendidos concluído (total SKUs=5696)
2025-07-15 06:51:47 [INFO] pipeline - Agregação: Merge dos dados agregados concluído: 86 linhas
2025-07-15 06:51:47 [INFO] pipeline - Agregação: CSV agregado salvo em data/interim/aggregated_sales.csv
2025-07-15 06:51:47 [INFO] pipeline - Agregação: Diretório Delta anterior removido: data/interim/aggregated_sales.delta
2025-07-15 06:51:47 [INFO] pipeline - Agregação: Delta agregado salvo em data/interim/aggregated_sales.delta
2025-07-15 06:51:47 [INFO] pipeline - Agregação macro concluída com sucesso
2025-07-15 06:51:56 [INFO] pipeline - Features: lendo Delta de data/processed/vendas_processed.delta
2025-07-15 06:51:56 [INFO] pipeline - Features: DataFrame carregado com shape (489856, 4)
2025-07-15 06:51:58 [INFO] pipeline - Features: features geradas; df_feats.shape=(489856, 14)
2025-07-15 06:52:00 [INFO] pipeline - ✔ CSV de features salvo em data/features/vendas_features.csv
2025-07-15 06:52:00 [INFO] pipeline - ✔ Delta de features salvo em data/features/vendas_features.delta
2025-07-15 06:52:13 [INFO] pipeline - SARIMA: Iniciando order=(1, 1, 1) seasonal=(1, 1, 1, 7)
2025-07-15 06:52:13 [INFO] pipeline - Série com frequência definida como <Day>
2025-07-15 06:52:13 [INFO] pipeline - ADF test d=0: p-value=0.0501
2025-07-15 06:52:13 [INFO] pipeline - ADF test d=1: p-value=0.0121
2025-07-15 06:52:13 [INFO] pipeline - Série final para modelagem d=1
2025-07-15 06:52:13 [INFO] pipeline - SARIMA ajustado com sucesso
2025-07-15 06:52:13 [INFO] pipeline - SARIMA metrics on historical split: {'rmse': 10263.561996229066, 'mae': 8082.068443348698, 'mape': np.float64(121.0441006339235), 'r2': 0.838303664202277, 'wmape': np.float64(1395.8667432381171)}
2025-07-15 06:52:13 [INFO] pipeline - SARIMA: Forecast gerado para o período 2024-04-09 até 2024-04-15
2025-07-15 06:52:13 [INFO] pipeline - SARIMA salvo em models/sarima_model.pkl
2025-07-15 06:52:13 [INFO] pipeline - SARIMA forecast exportado em data/models/sarima_forecast.csv
2025-07-15 06:52:14 [INFO] pipeline - Treinando LightGBM com {'objective': 'regression', 'metric': 'rmse'}
2025-07-15 06:52:16 [INFO] pipeline - ML forecast exportado em data/models/ml_forecast.csv
2025-07-15 06:52:16 [INFO] pipeline - LightGBM metrics: {'rmse': 6.321117964186915, 'mae': 1.6013831674023828, 'mape': np.float64(7.002794253756646), 'r2': 0.9550409671974993, 'wmape': np.float64(20.124671309551935)}
2025-07-15 06:52:16 [INFO] pipeline - LightGBM salvo em models/lgb_model.pkl
2025-07-15 06:52:16 [INFO] pipeline - Treinando CatBoost com {'verbose': 0}
2025-07-15 06:52:40 [INFO] pipeline - CatBoost forecast exportado em data/models/catboost_forecast.csv
2025-07-15 06:52:40 [INFO] pipeline - CatBoost metrics: {'rmse': 6.193205056994577, 'mae': 1.7003662737630383, 'mape': np.float64(15.847823653347906), 'r2': 0.956842121417274, 'wmape': np.float64(21.36859751113544)}
2025-07-15 06:52:40 [INFO] pipeline - CatBoost salvo em models/catboost_model.cbm
2025-07-15 06:52:40 [INFO] pipeline - Orquestração de treinamento finalizada.
2025-07-15 06:54:19,643 [INFO] pipeline - Iniciando avaliação de modelos
2025-07-15 06:58:04,500 [INFO] pipeline - Iniciando avaliação de modelos
2025-07-15 14:51:07,900 [INFO] pipeline - Iniciando avaliação de modelos
2025-07-15 20:37:53 [INFO] pipeline - Ingestão: iniciando leitura de data/raw/vendas.csv
2025-07-15 20:37:53 [INFO] pipeline - Ingestão: lido DataFrame com shape (135226, 3)
2025-07-15 20:37:53 [INFO] pipeline - Ingestão: colunas renomeadas para ['sku', 'data', 'vendas']
2025-07-15 20:37:54 [INFO] pipeline - Ingestão: dados salvos em Delta Lake: data/interim/vendas_interim.delta
2025-07-15 20:37:54 [INFO] pipeline - Ingestão: término da ingestão e armazenamento de versões.
2025-07-15 20:37:54 [INFO] pipeline - Ingestão finalizada com sucesso.
2025-07-15 20:40:13 [INFO] pipeline - Ingestão: iniciando leitura de data/raw/vendas.csv
2025-07-15 20:40:13 [INFO] pipeline - Ingestão: lido DataFrame com shape (135226, 3)
2025-07-15 20:40:13 [INFO] pipeline - Ingestão: colunas renomeadas para ['sku', 'data', 'vendas']
2025-07-15 20:40:13 [INFO] pipeline - Ingestão: dados salvos em Delta Lake: data/interim/vendas_interim.delta
2025-07-15 20:40:13 [INFO] pipeline - Ingestão: término da ingestão e armazenamento de versões.
2025-07-15 20:40:13 [INFO] pipeline - Ingestão finalizada com sucesso.
2025-07-15 20:48:45 INFO configuração de logging concluída
2025-07-15 20:48:45 INFO início da etapa de ingestão
2025-07-15 20:48:45 ERROR falha na ingestão de dados
Traceback (most recent call last):
  File "/home/data-vibe/github/project_time_series_forecasting/src/ingestion/loader.py", line 71, in run
    self._init_spark()
  File "/home/data-vibe/github/project_time_series_forecasting/src/ingestion/loader.py", line 33, in _init_spark
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/sql/session.py", line 556, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/core/context.py", line 523, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/core/context.py", line 205, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/core/context.py", line 444, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/java_gateway.py", line 111, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
2025-07-15 20:53:35 INFO configuração de logging concluída
2025-07-15 20:53:35 INFO início da etapa de ingestão
2025-07-15 20:53:36 ERROR falha na ingestão de dados
Traceback (most recent call last):
  File "/home/data-vibe/github/project_time_series_forecasting/src/ingestion/loader.py", line 71, in run
    self._init_spark()
  File "/home/data-vibe/github/project_time_series_forecasting/src/ingestion/loader.py", line 33, in _init_spark
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/sql/session.py", line 556, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/core/context.py", line 523, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/core/context.py", line 205, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/core/context.py", line 444, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/java_gateway.py", line 111, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
2025-07-15 20:56:36 INFO configuração de logging concluída
2025-07-15 20:56:36 INFO início da etapa de ingestão
2025-07-15 20:56:36 ERROR falha na ingestão de dados
Traceback (most recent call last):
  File "/home/data-vibe/github/project_time_series_forecasting/src/ingestion/loader.py", line 71, in run
    self._init_spark()
  File "/home/data-vibe/github/project_time_series_forecasting/src/ingestion/loader.py", line 33, in _init_spark
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/sql/session.py", line 556, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/core/context.py", line 523, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/core/context.py", line 205, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/core/context.py", line 444, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/java_gateway.py", line 111, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
2025-07-15 20:59:15 INFO configuração de logging concluída
2025-07-15 20:59:15 INFO início da etapa de ingestão
2025-07-15 20:59:15 ERROR falha na ingestão de dados
Traceback (most recent call last):
  File "/home/data-vibe/github/project_time_series_forecasting/src/ingestion/loader.py", line 71, in run
    self._init_spark()
  File "/home/data-vibe/github/project_time_series_forecasting/src/ingestion/loader.py", line 33, in _init_spark
    .getOrCreate()
     ^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/sql/session.py", line 556, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/core/context.py", line 523, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/core/context.py", line 205, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/core/context.py", line 444, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
                                       ^^^^^^^^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/java_gateway.py", line 111, in launch_gateway
    raise PySparkRuntimeError(
pyspark.errors.exceptions.base.PySparkRuntimeError: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.
2025-07-15 20:59:58 INFO configuração de logging concluída
2025-07-15 20:59:58 INFO início da etapa de ingestão
2025-07-15 21:00:03 INFO SparkSession iniciada
2025-07-15 21:00:09 INFO raw data carregada: 135226 linhas, 3 colunas
2025-07-15 21:00:10 INFO interim CSV salvo em data/interim/vendas_interim.csv
2025-07-15 21:00:11 ERROR falha na ingestão de dados
Traceback (most recent call last):
  File "/home/data-vibe/github/project_time_series_forecasting/src/ingestion/loader.py", line 74, in run
    self.save_delta(df)
  File "/home/data-vibe/github/project_time_series_forecasting/src/ingestion/loader.py", line 65, in save_delta
    .save(str(out_dir))
     ^^^^^^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/sql/readwriter.py", line 1745, in save
    self._jwrite.save(path)
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/py4j/java_gateway.py", line 1362, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", line 282, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/py4j/protocol.py", line 327, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o45.save.
: org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: delta. Make sure the provider name is correct and the package is properly registered and compatible with your Spark version. SQLSTATE: 42K02
	at org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:722)
	at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:681)
	at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:740)
	at org.apache.spark.sql.classic.DataFrameWriter.lookupV2Provider(DataFrameWriter.scala:626)
	at org.apache.spark.sql.classic.DataFrameWriter.saveInternal(DataFrameWriter.scala:135)
	at org.apache.spark.sql.classic.DataFrameWriter.save(DataFrameWriter.scala:118)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:108)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: delta.DefaultSource
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$6(DataSource.scala:665)
	at scala.util.Try$.apply(Try.scala:217)
	at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:665)
	at scala.util.Failure.orElse(Try.scala:230)
	at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:665)
	... 16 more

2025-07-15 21:00:12 INFO SparkSession finalizada
2025-07-15 21:00:12 INFO Closing down clientserver connection
2025-07-15 21:02:00 INFO configuração de logging concluída
2025-07-15 21:02:00 INFO início da etapa de ingestão
2025-07-15 21:02:05 INFO SparkSession iniciada
2025-07-15 21:02:10 INFO raw data carregada: 135226 linhas, 3 colunas
2025-07-15 21:02:11 INFO interim CSV salvo em data/interim/vendas_interim.csv
2025-07-15 21:02:12 ERROR falha na ingestão de dados
Traceback (most recent call last):
  File "/home/data-vibe/github/project_time_series_forecasting/src/ingestion/loader.py", line 74, in run
    self.save_delta(df)
  File "/home/data-vibe/github/project_time_series_forecasting/src/ingestion/loader.py", line 65, in save_delta
    .save(str(out_dir))
     ^^^^^^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/sql/readwriter.py", line 1745, in save
    self._jwrite.save(path)
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/py4j/java_gateway.py", line 1362, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", line 282, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/py4j/protocol.py", line 327, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o45.save.
: org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: delta. Make sure the provider name is correct and the package is properly registered and compatible with your Spark version. SQLSTATE: 42K02
	at org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:722)
	at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:681)
	at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:740)
	at org.apache.spark.sql.classic.DataFrameWriter.lookupV2Provider(DataFrameWriter.scala:626)
	at org.apache.spark.sql.classic.DataFrameWriter.saveInternal(DataFrameWriter.scala:135)
	at org.apache.spark.sql.classic.DataFrameWriter.save(DataFrameWriter.scala:118)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:108)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: delta.DefaultSource
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$6(DataSource.scala:665)
	at scala.util.Try$.apply(Try.scala:217)
	at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:665)
	at scala.util.Failure.orElse(Try.scala:230)
	at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:665)
	... 16 more

2025-07-15 21:02:12 INFO SparkSession finalizada
2025-07-15 21:02:12 INFO Closing down clientserver connection
2025-07-15 21:08:25 INFO configuração de logging concluída
2025-07-15 21:08:25 INFO início da etapa de ingestão
2025-07-15 21:08:49 INFO SparkSession com suporte a Delta iniciada
2025-07-15 21:08:54 INFO raw data carregada: 135226 linhas, 3 colunas
2025-07-15 21:08:55 INFO interim CSV salvo em data/interim/vendas_interim.csv
2025-07-15 21:08:55 ERROR falha na ingestão de dados
Traceback (most recent call last):
  File "/home/data-vibe/github/project_time_series_forecasting/src/ingestion/loader.py", line 74, in run
    self.save_delta(df)
  File "/home/data-vibe/github/project_time_series_forecasting/src/ingestion/loader.py", line 65, in save_delta
    .save(str(out_dir))
     ^^^^^^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/sql/readwriter.py", line 1745, in save
    self._jwrite.save(path)
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/py4j/java_gateway.py", line 1362, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", line 288, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [DELTA_CONFIGURE_SPARK_SESSION_WITH_EXTENSION_AND_CATALOG] This Delta operation requires the SparkSession to be configured with the
DeltaSparkSessionExtension and the DeltaCatalog. Please set the necessary
configurations when creating the SparkSession as shown below.

  SparkSession.builder()
    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension")
    .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog")
    ...
    .getOrCreate()

If you are using spark-shell/pyspark/spark-submit, you can add the required configurations to the command as show below:
--conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog

2025-07-15 21:08:55 INFO SparkSession finalizada
2025-07-15 21:08:55 INFO Closing down clientserver connection
2025-07-15 21:09:32 INFO configuração de logging concluída
2025-07-15 21:09:32 INFO início da etapa de ingestão
2025-07-15 21:09:38 INFO SparkSession com suporte a Delta iniciada
2025-07-15 21:09:42 INFO raw data carregada: 135226 linhas, 3 colunas
2025-07-15 21:09:43 INFO interim CSV salvo em data/interim/vendas_interim.csv
2025-07-15 21:09:44 ERROR falha na ingestão de dados
Traceback (most recent call last):
  File "/home/data-vibe/github/project_time_series_forecasting/src/ingestion/loader.py", line 74, in run
    self.save_delta(df)
  File "/home/data-vibe/github/project_time_series_forecasting/src/ingestion/loader.py", line 65, in save_delta
    .save(str(out_dir))
     ^^^^^^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/sql/readwriter.py", line 1745, in save
    self._jwrite.save(path)
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/py4j/java_gateway.py", line 1362, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", line 288, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [DELTA_CONFIGURE_SPARK_SESSION_WITH_EXTENSION_AND_CATALOG] This Delta operation requires the SparkSession to be configured with the
DeltaSparkSessionExtension and the DeltaCatalog. Please set the necessary
configurations when creating the SparkSession as shown below.

  SparkSession.builder()
    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension")
    .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog")
    ...
    .getOrCreate()

If you are using spark-shell/pyspark/spark-submit, you can add the required configurations to the command as show below:
--conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog

2025-07-15 21:09:44 INFO SparkSession finalizada
2025-07-15 21:09:44 INFO Closing down clientserver connection
2025-07-15 21:11:35 INFO configuração de logging concluída
2025-07-15 21:11:35 INFO início da etapa de ingestão
2025-07-15 21:11:43 INFO SparkSession com suporte a Delta iniciada
2025-07-15 21:11:47 INFO raw data carregada: 135226 linhas, 3 colunas
2025-07-15 21:11:48 INFO interim CSV salvo em data/interim/vendas_interim.csv
2025-07-15 21:11:49 ERROR falha na ingestão de dados
Traceback (most recent call last):
  File "/home/data-vibe/github/project_time_series_forecasting/src/ingestion/loader.py", line 76, in run
    self.save_delta(df)
  File "/home/data-vibe/github/project_time_series_forecasting/src/ingestion/loader.py", line 67, in save_delta
    .save(str(out_dir))
     ^^^^^^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/sql/readwriter.py", line 1745, in save
    self._jwrite.save(path)
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/py4j/java_gateway.py", line 1362, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", line 288, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [DELTA_FAILED_TO_MERGE_FIELDS] Failed to merge fields 'sku' and 'sku'
2025-07-15 21:11:49 INFO SparkSession finalizada
2025-07-15 21:11:49 INFO Closing down clientserver connection
2025-07-15 21:15:06 INFO configuração de logging concluída
2025-07-15 21:15:06 INFO início da etapa de ingestão
2025-07-15 21:15:13 INFO SparkSession com suporte a Delta iniciada
2025-07-15 21:15:17 INFO raw data carregada: 135226 linhas, 3 colunas
2025-07-15 21:15:18 INFO interim CSV salvo em data/interim/vendas_interim.csv
2025-07-15 21:15:24 INFO interim Delta salvo em data/interim/vendas_interim.delta
2025-07-15 21:15:24 INFO ingestão concluída com sucesso
2025-07-15 21:15:24 INFO SparkSession finalizada
2025-07-15 21:15:24 INFO Closing down clientserver connection
2025-07-15 21:17:49 INFO configuração de logging concluída
2025-07-15 21:17:49 INFO início da etapa de ingestão
2025-07-15 21:17:56 INFO SparkSession com suporte a Delta iniciada
2025-07-15 21:18:01 INFO raw data carregada: 135226 linhas, 3 colunas
2025-07-15 21:18:02 INFO interim CSV salvo em data/interim/vendas_interim.csv
2025-07-15 21:18:08 INFO interim Delta salvo em data/interim/vendas_interim.delta
2025-07-15 21:18:08 INFO ingestão concluída com sucesso
2025-07-15 21:18:08 INFO SparkSession finalizada
2025-07-15 21:18:08 INFO Closing down clientserver connection
2025-07-15 21:21:51 INFO configuração de logging concluída
2025-07-15 21:21:51 INFO ==== INÍCIO DA ETAPA DE INGESTÃO ====
2025-07-15 21:21:59 INFO SparkSession com suporte a Delta iniciada
2025-07-15 21:22:04 INFO raw data carregada: 135226 linhas, 3 colunas
2025-07-15 21:22:05 INFO interim CSV salvo em data/interim/vendas_interim.csv
2025-07-15 21:22:12 INFO interim Delta salvo em data/interim/vendas_interim.delta
2025-07-15 21:22:12 INFO ==== FIM DA ETAPA DE INGESTÃO ====
2025-07-15 21:22:12 INFO ingestão concluída com sucesso
2025-07-15 21:22:13 INFO SparkSession finalizada
2025-07-15 21:22:13 INFO Closing down clientserver connection
2025-07-15 21:29:17 INFO configuração de logging concluída
2025-07-15 21:29:17 INFO ==== INÍCIO DA ETAPA DE INGESTÃO ====
2025-07-15 21:29:23 INFO SparkSession com suporte a Delta iniciada
2025-07-15 21:29:28 INFO raw data carregada: 135226 linhas, 3 colunas
2025-07-15 21:29:29 INFO interim CSV salvo em data/interim/vendas_interim.csv
2025-07-15 21:29:35 INFO interim Delta salvo em data/interim/vendas_interim.delta
2025-07-15 21:29:35 INFO ==== FIM DA ETAPA DE INGESTÃO ====
2025-07-15 21:29:35 INFO ingestão concluída com sucesso
2025-07-15 21:29:35 INFO SparkSession finalizada
2025-07-15 21:29:35 INFO Closing down clientserver connection
2025-07-15 21:29:47 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE PREPROCESSAMENTO ====
2025-07-15 21:29:53 [INFO] pipeline - SparkSession com suporte a Delta iniciada
2025-07-15 21:29:53 [INFO] pipeline - ==== INÍCIO DA ETAPA DE PREPROCESSAMENTO ====
2025-07-15 21:29:53 [INFO] pipeline - lendo Delta de entrada em data/interim/vendas_interim.delta
2025-07-15 21:29:54 [ERROR] DataFrameQueryContextLogger - [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `data` cannot be resolved. Did you mean one of the following? [`sku`, `venda`, `data_venda`]. SQLSTATE: 42703
Traceback (most recent call last):
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", line 282, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/py4j/protocol.py", line 327, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o41.select.
: org.apache.spark.sql.AnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `data` cannot be resolved. Did you mean one of the following? [`sku`, `venda`, `data_venda`]. SQLSTATE: 42703;
'Project [sku#0, unresolvedalias(cast('data as date)), venda#2]
+- Relation [sku#0,data_venda#1,venda#2] parquet

	at org.apache.spark.sql.errors.QueryCompilationErrors$.unresolvedAttributeError(QueryCompilationErrors.scala:401)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$failUnresolvedAttribute(CheckAnalysis.scala:169)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7(CheckAnalysis.scala:404)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7$adapted(CheckAnalysis.scala:402)
	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)
	at scala.collection.immutable.Vector.foreach(Vector.scala:2125)
	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)
	at scala.collection.immutable.Vector.foreach(Vector.scala:2125)
	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6(CheckAnalysis.scala:402)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6$adapted(CheckAnalysis.scala:402)
	at scala.collection.immutable.List.foreach(List.scala:334)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:402)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:284)
	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:284)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:255)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:249)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:244)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:231)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:249)
	at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:192)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
	at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:192)
	at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)
	at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)
	at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:280)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:280)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)
	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)
	at scala.util.Try$.apply(Try.scala:217)
	at org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)
	at org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1439)
	at org.apache.spark.util.LazyTry.get(LazyTry.scala:58)
	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:121)
	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:80)
	at org.apache.spark.sql.classic.Dataset$.$anonfun$ofRows$1(Dataset.scala:115)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)
	at org.apache.spark.sql.classic.Dataset$.ofRows(Dataset.scala:113)
	at org.apache.spark.sql.classic.Dataset.withPlan(Dataset.scala:2263)
	at org.apache.spark.sql.classic.Dataset.select(Dataset.scala:894)
	at org.apache.spark.sql.classic.Dataset.select(Dataset.scala:232)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:108)
	at java.base/java.lang.Thread.run(Thread.java:840)
	Suppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller
		at org.apache.spark.sql.errors.QueryCompilationErrors$.unresolvedAttributeError(QueryCompilationErrors.scala:401)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$failUnresolvedAttribute(CheckAnalysis.scala:169)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7(CheckAnalysis.scala:404)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7$adapted(CheckAnalysis.scala:402)
		at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)
		at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)
		at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)
		at scala.collection.immutable.Vector.foreach(Vector.scala:2125)
		at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)
		at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)
		at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)
		at scala.collection.immutable.Vector.foreach(Vector.scala:2125)
		at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6(CheckAnalysis.scala:402)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6$adapted(CheckAnalysis.scala:402)
		at scala.collection.immutable.List.foreach(List.scala:334)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:402)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:284)
		at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:284)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:255)
		at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:249)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:244)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:231)
		at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:249)
		at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:192)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
		at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
		at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:192)
		at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)
		at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)
		at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)
		at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:280)
		at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)
		at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:280)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)
		at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)
		at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)
		at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)
		at scala.util.Try$.apply(Try.scala:217)
		at org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)
		at org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)
		at org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)
		... 21 more

2025-07-15 21:29:54 [INFO] py4j.clientserver - Closing down clientserver connection
2025-07-15 21:33:29 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE PREPROCESSAMENTO ====
2025-07-15 21:33:35 [INFO] pipeline - SparkSession com suporte a Delta iniciada
2025-07-15 21:33:35 [INFO] pipeline - ==== INÍCIO DA ETAPA DE PREPROCESSAMENTO ====
2025-07-15 21:33:35 [INFO] pipeline - lendo Delta de entrada em data/interim/vendas_interim.delta
2025-07-15 21:33:41 [INFO] pipeline - dados brutos carregados: 135226 linhas
2025-07-15 21:33:41 [INFO] pipeline - agrupadas duplicatas por sku+data
2025-07-15 21:33:41 [INFO] pipeline - gerada malha completa de datas por SKU
2025-07-15 21:33:41 [INFO] pipeline - marcado campo is_imputed
2025-07-15 21:33:41 [INFO] pipeline - preenchidos valores nulos de venda com zero
2025-07-15 21:33:41 [INFO] pipeline - ordenado por sku e data
2025-07-15 21:33:46 [INFO] pipeline - CSV processado salvo em data/processed/vendas_processed.csv
2025-07-15 21:33:46 [INFO] py4j.clientserver - Closing down clientserver connection
2025-07-15 21:36:25 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE PREPROCESSAMENTO ====
2025-07-15 21:36:31 [INFO] pipeline - SparkSession com suporte a Delta iniciada
2025-07-15 21:36:31 [INFO] pipeline - ==== INÍCIO DA ETAPA DE PREPROCESSAMENTO ====
2025-07-15 21:36:31 [INFO] pipeline - lendo Delta de entrada em data/interim/vendas_interim.delta
2025-07-15 21:36:38 [INFO] pipeline - dados brutos carregados: 135226 linhas
2025-07-15 21:36:38 [INFO] pipeline - agrupadas duplicatas por sku+data
2025-07-15 21:36:38 [INFO] pipeline - gerada malha completa de datas por SKU
2025-07-15 21:36:38 [INFO] pipeline - marcado campo is_imputed
2025-07-15 21:36:38 [INFO] pipeline - preenchidos valores nulos de venda com zero
2025-07-15 21:36:38 [INFO] pipeline - ordenado por sku e data
2025-07-15 21:36:42 [INFO] pipeline - CSV processado salvo em data/processed/vendas_processed.csv
2025-07-15 21:36:45 [INFO] pipeline - Delta processado salvo em data/processed/vendas_processed.delta
2025-07-15 21:36:45 [INFO] pipeline - ==== FIM DA ETAPA DE PREPROCESSAMENTO ====
2025-07-15 21:36:46 [INFO] pipeline - SparkSession finalizada
2025-07-15 21:36:46 [INFO] py4j.clientserver - Closing down clientserver connection
2025-07-15 21:42:52 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE FEATURE ENGINEERING ====
2025-07-15 21:42:58 [INFO] pipeline - SparkSession com suporte a Delta iniciada para features
2025-07-15 21:42:58 [INFO] pipeline - ==== INÍCIO DA FEATURE ENGINEERING ====
2025-07-15 21:42:58 [INFO] pipeline - Features: lendo Delta de entrada em data/processed/vendas_processed.delta
2025-07-15 21:43:00 [ERROR] DataFrameQueryContextLogger - [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `vendas` cannot be resolved. Did you mean one of the following? [`venda`, `data`, `sku`, `is_imputed`]. SQLSTATE: 42703
Traceback (most recent call last):
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py", line 282, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "/home/data-vibe/github/project_time_series_forecasting/.venv/lib/python3.12/site-packages/py4j/protocol.py", line 327, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o41.select.
: org.apache.spark.sql.AnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `vendas` cannot be resolved. Did you mean one of the following? [`venda`, `data`, `sku`, `is_imputed`]. SQLSTATE: 42703;
'Project [sku#0, cast(data#1 as date) AS data#4, 'vendas AS venda#5, is_imputed#3 AS is_imputed#6]
+- Relation [sku#0,data#1,venda#2L,is_imputed#3] parquet

	at org.apache.spark.sql.errors.QueryCompilationErrors$.unresolvedAttributeError(QueryCompilationErrors.scala:401)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$failUnresolvedAttribute(CheckAnalysis.scala:169)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7(CheckAnalysis.scala:404)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7$adapted(CheckAnalysis.scala:402)
	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)
	at scala.collection.immutable.Vector.foreach(Vector.scala:2125)
	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6(CheckAnalysis.scala:402)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6$adapted(CheckAnalysis.scala:402)
	at scala.collection.immutable.List.foreach(List.scala:334)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:402)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:284)
	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:284)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:255)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:249)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:244)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:231)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:249)
	at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:192)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
	at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:192)
	at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)
	at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)
	at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:280)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:280)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)
	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)
	at scala.util.Try$.apply(Try.scala:217)
	at org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)
	at org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1439)
	at org.apache.spark.util.LazyTry.get(LazyTry.scala:58)
	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:121)
	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:80)
	at org.apache.spark.sql.classic.Dataset$.$anonfun$ofRows$1(Dataset.scala:115)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)
	at org.apache.spark.sql.classic.Dataset$.ofRows(Dataset.scala:113)
	at org.apache.spark.sql.classic.Dataset.withPlan(Dataset.scala:2263)
	at org.apache.spark.sql.classic.Dataset.select(Dataset.scala:894)
	at org.apache.spark.sql.classic.Dataset.select(Dataset.scala:232)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:108)
	at java.base/java.lang.Thread.run(Thread.java:840)
	Suppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller
		at org.apache.spark.sql.errors.QueryCompilationErrors$.unresolvedAttributeError(QueryCompilationErrors.scala:401)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.org$apache$spark$sql$catalyst$analysis$CheckAnalysis$$failUnresolvedAttribute(CheckAnalysis.scala:169)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7(CheckAnalysis.scala:404)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$7$adapted(CheckAnalysis.scala:402)
		at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)
		at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:251)
		at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:251)
		at scala.collection.immutable.Vector.foreach(Vector.scala:2125)
		at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:251)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6(CheckAnalysis.scala:402)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6$adapted(CheckAnalysis.scala:402)
		at scala.collection.immutable.List.foreach(List.scala:334)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:402)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:284)
		at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:252)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:284)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:255)
		at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:249)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:244)
		at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:231)
		at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:249)
		at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:192)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
		at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
		at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:192)
		at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)
		at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)
		at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)
		at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:280)
		at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:423)
		at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:280)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:110)
		at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:278)
		at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:278)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)
		at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:277)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:110)
		at scala.util.Try$.apply(Try.scala:217)
		at org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)
		at org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)
		at org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)
		... 21 more

2025-07-15 21:43:00 [INFO] py4j.clientserver - Closing down clientserver connection
2025-07-15 21:44:23 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE FEATURE ENGINEERING ====
2025-07-15 21:44:29 [INFO] pipeline - SparkSession com suporte a Delta iniciada para features
2025-07-15 21:44:29 [INFO] pipeline - ==== INÍCIO DA FEATURE ENGINEERING ====
2025-07-15 21:44:29 [INFO] pipeline - Features: lendo Delta de entrada em data/processed/vendas_processed.delta
2025-07-15 21:44:38 [INFO] pipeline - Features: dados brutos carregados (230704 linhas)
2025-07-15 21:44:38 [INFO] pipeline - Features: flag de imputação criado
2025-07-15 21:44:38 [INFO] pipeline - Features: lags [1, 7, 14] criados
2025-07-15 21:44:38 [INFO] pipeline - Features: rolling windows [7, 14, 30] criados
2025-07-15 21:44:38 [INFO] pipeline - Features: variáveis de calendário criadas
2025-07-15 21:44:42 [INFO] pipeline - Features: CSV salvo em data/features/vendas_features.csv
2025-07-15 21:44:45 [INFO] pipeline - Features: Delta salvo em data/features/vendas_features.delta
2025-07-15 21:44:45 [INFO] pipeline - ==== FIM DA FEATURE ENGINEERING ====
2025-07-15 21:44:46 [INFO] pipeline - SparkSession finalizada
2025-07-15 21:44:46 [INFO] py4j.clientserver - Closing down clientserver connection
2025-07-15 22:00:17 [INFO] pipeline - ==== INÍCIO DO TREINO LIGHTGBM ====
2025-07-15 22:00:17 [INFO] pipeline - Carregando features de data/features/vendas_features.csv
2025-07-15 22:04:25 [INFO] pipeline - ==== INÍCIO DO TREINO LIGHTGBM ====
2025-07-15 22:04:25 [INFO] pipeline - Carregando features de data/features/vendas_features.csv
2025-07-15 22:04:25 [INFO] pipeline - Dados carregados: 230704 linhas, 14 colunas
2025-07-15 22:08:47 [INFO] pipeline - ==== INÍCIO DO TREINO LIGHTGBM ====
2025-07-15 22:08:47 [INFO] pipeline - Carregando features de data/features/vendas_features.csv
2025-07-15 22:08:47 [INFO] pipeline - Dados carregados: 230704 linhas, 14 colunas
2025-07-15 22:15:56 [INFO] pipeline - ==== INÍCIO DO TREINO LIGHTGBM ====
2025-07-15 22:15:56 [INFO] pipeline - Carregando features de data/features/vendas_features.csv
2025-07-15 22:15:56 [INFO] pipeline - Dados carregados: 230704 linhas, 14 colunas
2025-07-15 22:15:57 [INFO] pipeline - fold 1/5 RMSE: 5.0482
2025-07-15 22:15:58 [INFO] pipeline - fold 2/5 RMSE: 6.2112
2025-07-15 22:15:59 [INFO] pipeline - fold 3/5 RMSE: 80.1813
2025-07-15 22:16:00 [INFO] pipeline - fold 4/5 RMSE: 4.9465
2025-07-15 22:16:01 [INFO] pipeline - fold 5/5 RMSE: 4.8540
2025-07-15 22:16:02 [INFO] pipeline - CV RMSE média: 20.2483  desvio: 33.5081
2025-07-15 22:16:02 [INFO] pipeline - Treinando LightGBM no dataset completo
2025-07-15 22:16:03 [INFO] pipeline - Modelo salvo em data/models/lgbm_model.pkl
2025-07-15 22:16:08 [INFO] pipeline - Forecast criado para 7 dias
2025-07-15 22:16:08 [INFO] pipeline - Forecast salvo em data/models/ml_forecast.csv
2025-07-15 22:16:08 [INFO] pipeline - ==== FIM DO TREINO LIGHTGBM ====
2025-07-15 22:21:21 [INFO] pipeline - ==== INÍCIO DO TREINO CATBOOST ====
2025-07-15 22:21:21 [INFO] pipeline - Lendo features de data/features/vendas_features.csv
2025-07-15 22:21:22 [INFO] pipeline - Dados carregados: 230704 linhas, 14 colunas (arquivo: data/features/vendas_features.csv/part-00000-5393d33c-7a86-4c4a-9088-fb736837fc97-c000.csv)
2025-07-15 22:21:22 [INFO] pipeline - fold 1/5 RMSE: 5.1635
2025-07-15 22:21:23 [INFO] pipeline - fold 2/5 RMSE: 6.2760
2025-07-15 22:21:23 [INFO] pipeline - fold 3/5 RMSE: 80.3538
2025-07-15 22:21:24 [INFO] pipeline - fold 4/5 RMSE: 5.2489
2025-07-15 22:21:26 [INFO] pipeline - fold 5/5 RMSE: 5.1353
2025-07-15 22:21:26 [INFO] pipeline - CV RMSE média: 20.4355  desvio: 33.4987
2025-07-15 22:21:26 [INFO] pipeline - Treinando CatBoost no dataset completo
2025-07-15 22:21:28 [INFO] pipeline - Modelo salvo em data/models/catboost_model.cbm
2025-07-15 22:21:32 [INFO] pipeline - Forecast CatBoost criado para 7 dias
2025-07-15 22:21:33 [INFO] pipeline - Forecast salvo em data/models/catboost_forecast.csv
2025-07-15 22:21:33 [INFO] pipeline - ==== FIM DO TREINO CATBOOST ====
2025-07-15 22:21:51 [INFO] pipeline - ==== INÍCIO DO TREINO CATBOOST ====
2025-07-15 22:21:51 [INFO] pipeline - Lendo features de data/features/vendas_features.csv
2025-07-15 22:21:51 [INFO] pipeline - Dados carregados: 230704 linhas, 14 colunas (arquivo: data/features/vendas_features.csv/part-00000-5393d33c-7a86-4c4a-9088-fb736837fc97-c000.csv)
2025-07-15 22:21:52 [INFO] pipeline - fold 1/5 RMSE: 5.1635
2025-07-15 22:21:52 [INFO] pipeline - fold 2/5 RMSE: 6.2760
2025-07-15 22:21:53 [INFO] pipeline - fold 3/5 RMSE: 80.3538
2025-07-15 22:21:53 [INFO] pipeline - fold 4/5 RMSE: 5.2489
2025-07-15 22:21:54 [INFO] pipeline - fold 5/5 RMSE: 5.1353
2025-07-15 22:21:54 [INFO] pipeline - CV RMSE média: 20.4355  desvio: 33.4987
2025-07-15 22:21:54 [INFO] pipeline - Treinando CatBoost no dataset completo
2025-07-15 22:21:56 [INFO] pipeline - Modelo salvo em data/models/catboost_model.cbm
2025-07-15 22:22:01 [INFO] pipeline - Forecast CatBoost criado para 7 dias
2025-07-15 22:22:01 [INFO] pipeline - Forecast salvo em data/models/catboost_forecast.csv
2025-07-15 22:22:01 [INFO] pipeline - ==== FIM DO TREINO CATBOOST ====
2025-07-15 22:22:13 [INFO] pipeline - ==== INÍCIO DO TREINO CATBOOST ====
2025-07-15 22:22:13 [INFO] pipeline - Lendo features de data/features/vendas_features.csv
2025-07-15 22:22:13 [INFO] pipeline - Dados carregados: 230704 linhas, 14 colunas (arquivo: data/features/vendas_features.csv/part-00000-5393d33c-7a86-4c4a-9088-fb736837fc97-c000.csv)
2025-07-15 22:22:13 [INFO] pipeline - fold 1/5 RMSE: 5.1635
2025-07-15 22:22:14 [INFO] pipeline - fold 2/5 RMSE: 6.2760
2025-07-15 22:22:15 [INFO] pipeline - fold 3/5 RMSE: 80.3538
2025-07-15 22:22:15 [INFO] pipeline - fold 4/5 RMSE: 5.2489
2025-07-15 22:22:16 [INFO] pipeline - fold 5/5 RMSE: 5.1353
2025-07-15 22:22:16 [INFO] pipeline - CV RMSE média: 20.4355  desvio: 33.4987
2025-07-15 22:22:16 [INFO] pipeline - Treinando CatBoost no dataset completo
2025-07-15 22:22:19 [INFO] pipeline - Modelo salvo em data/models/catboost_model.cbm
2025-07-15 22:22:23 [INFO] pipeline - Forecast CatBoost criado para 7 dias
2025-07-15 22:22:24 [INFO] pipeline - Forecast salvo em data/models/catboost_forecast.csv
2025-07-15 22:22:24 [INFO] pipeline - ==== FIM DO TREINO CATBOOST ====
2025-07-15 22:26:54 [INFO] pipeline - ==== INÍCIO DO TREINO CATBOOST ====
2025-07-15 22:26:54 [INFO] pipeline - Lendo features de data/features/vendas_features.csv
2025-07-15 22:26:55 [INFO] pipeline - Dados carregados: 230704 linhas, 14 colunas (arquivo: data/features/vendas_features.csv/part-00000-5393d33c-7a86-4c4a-9088-fb736837fc97-c000.csv)
2025-07-15 22:26:55 [INFO] pipeline - fold 1/5 RMSE: 5.1635
2025-07-15 22:27:04 [INFO] pipeline - ==== INÍCIO DO TREINO CATBOOST ====
2025-07-15 22:27:04 [INFO] pipeline - Lendo features de data/features/vendas_features.csv
2025-07-15 22:27:04 [INFO] pipeline - Dados carregados: 230704 linhas, 14 colunas (arquivo: data/features/vendas_features.csv/part-00000-5393d33c-7a86-4c4a-9088-fb736837fc97-c000.csv)
2025-07-15 22:27:04 [INFO] pipeline - fold 1/5 RMSE: 5.1635
2025-07-15 22:32:59 [INFO] pipeline - ==== INÍCIO DO TREINO CATBOOST ====
2025-07-15 22:32:59 [INFO] pipeline - Lendo features de data/features/vendas_features.csv
2025-07-15 22:32:59 [INFO] pipeline - Dados carregados: 230704 linhas, 14 colunas (arquivo: data/features/vendas_features.csv/part-00000-5393d33c-7a86-4c4a-9088-fb736837fc97-c000.csv)
2025-07-15 22:32:59 [INFO] pipeline - fold 1/5 RMSE: 5.1635
2025-07-15 22:32:59 [INFO] pipeline - fold 1/5 — RMSE: 5.1635, MAE: 2.6137, MAPE: 21.15%, WMAPE: 22.48%, R²: 0.8896
2025-07-15 22:33:00 [INFO] pipeline - fold 2/5 RMSE: 6.2760
2025-07-15 22:33:00 [INFO] pipeline - fold 2/5 — RMSE: 6.2760, MAE: 3.5579, MAPE: 19.80%, WMAPE: 20.05%, R²: 0.9042
2025-07-15 22:33:01 [INFO] pipeline - fold 3/5 RMSE: 80.3538
2025-07-15 22:33:01 [INFO] pipeline - fold 3/5 — RMSE: 80.3538, MAE: 7.6103, MAPE: 19.52%, WMAPE: 37.94%, R²: 0.2118
2025-07-15 22:33:01 [INFO] pipeline - fold 4/5 RMSE: 5.2489
2025-07-15 22:33:01 [INFO] pipeline - fold 4/5 — RMSE: 5.2489, MAE: 2.6281, MAPE: 27.03%, WMAPE: 23.40%, R²: 0.8903
2025-07-15 22:33:02 [INFO] pipeline - fold 5/5 RMSE: 5.1353
2025-07-15 22:33:02 [INFO] pipeline - fold 5/5 — RMSE: 5.1353, MAE: 2.7299, MAPE: 24.69%, WMAPE: 22.95%, R²: 0.8722
2025-07-15 22:33:02 [INFO] pipeline - CV RMSE média: 20.4355  desvio: 33.4987
2025-07-15 22:33:02 [INFO] pipeline - cross-validation concluído
2025-07-15 22:33:02 [INFO] pipeline - Treinando CatBoost no dataset completo
2025-07-15 22:33:04 [INFO] pipeline - Modelo salvo em data/models/catboost_model.cbm
2025-07-15 22:33:11 [INFO] pipeline - Forecast CatBoost criado para 7 dias
2025-07-15 22:33:11 [INFO] pipeline - Forecast salvo em data/models/catboost_forecast.csv
2025-07-15 22:33:11 [INFO] pipeline - ==== FIM DO TREINO CATBOOST ====
2025-07-15 22:40:48 [INFO] pipeline - ==== INÍCIO DO TREINO LIGHTGBM ====
2025-07-15 22:40:48 [INFO] pipeline - Carregando features de data/features/vendas_features.csv
2025-07-15 22:40:49 [INFO] pipeline - Dados carregados: 230704 linhas, 14 colunas
2025-07-15 22:40:49 [INFO] pipeline - fold 1/5 — RMSE: 5.0482, MAE: 2.5093, MAPE: 14.66%, WMAPE: 21.59%, R²: 0.8944
2025-07-15 22:40:50 [INFO] pipeline - fold 2/5 — RMSE: 6.2112, MAE: 3.5017, MAPE: 17.01%, WMAPE: 19.73%, R²: 0.9062
2025-07-15 22:40:51 [INFO] pipeline - fold 3/5 — RMSE: 80.1813, MAE: 7.5134, MAPE: 15.59%, WMAPE: 37.46%, R²: 0.2152
2025-07-15 22:40:52 [INFO] pipeline - fold 4/5 — RMSE: 4.9465, MAE: 2.4113, MAPE: 14.83%, WMAPE: 21.47%, R²: 0.9025
2025-07-15 22:40:54 [INFO] pipeline - fold 5/5 — RMSE: 4.8540, MAE: 2.5403, MAPE: 15.32%, WMAPE: 21.36%, R²: 0.8858
2025-07-15 22:40:54 [INFO] pipeline - CV RMSE média: 20.2483  desvio: 33.5081
2025-07-15 22:40:54 [INFO] pipeline - Treinando LightGBM no dataset completo
2025-07-15 22:40:55 [INFO] pipeline - Modelo salvo em data/models/lgbm_model.pkl
2025-07-15 22:41:00 [INFO] pipeline - Forecast criado para 7 dias
2025-07-15 22:41:00 [INFO] pipeline - Forecast salvo em data/models/ml_forecast.csv
2025-07-15 22:41:00 [INFO] pipeline - ==== FIM DO TREINO LIGHTGBM ====
2025-07-15 22:42:04 [INFO] pipeline - ==== INÍCIO DO TREINO CATBOOST ====
2025-07-15 22:42:04 [INFO] pipeline - Lendo features de data/features/vendas_features.csv
2025-07-15 22:42:04 [INFO] pipeline - Dados carregados: 230704 linhas, 14 colunas (arquivo: data/features/vendas_features.csv/part-00000-5393d33c-7a86-4c4a-9088-fb736837fc97-c000.csv)
2025-07-15 22:42:05 [INFO] pipeline - fold 1/5 — RMSE: 5.1635, MAE: 2.6137, MAPE: 21.15%, WMAPE: 22.48%, R²: 0.8896
2025-07-15 22:42:05 [INFO] pipeline - fold 2/5 — RMSE: 6.2760, MAE: 3.5579, MAPE: 19.80%, WMAPE: 20.05%, R²: 0.9042
2025-07-15 22:42:06 [INFO] pipeline - fold 3/5 — RMSE: 80.3538, MAE: 7.6103, MAPE: 19.52%, WMAPE: 37.94%, R²: 0.2118
2025-07-15 22:42:07 [INFO] pipeline - fold 4/5 — RMSE: 5.2489, MAE: 2.6281, MAPE: 27.03%, WMAPE: 23.40%, R²: 0.8903
2025-07-15 22:42:08 [INFO] pipeline - fold 5/5 — RMSE: 5.1353, MAE: 2.7299, MAPE: 24.69%, WMAPE: 22.95%, R²: 0.8722
2025-07-15 22:42:08 [INFO] pipeline - CV RMSE média: 20.4355  desvio: 33.4987
2025-07-15 22:42:08 [INFO] pipeline - cross-validation concluído
2025-07-15 22:42:08 [INFO] pipeline - Treinando CatBoost no dataset completo
2025-07-15 22:42:10 [INFO] pipeline - Modelo salvo em data/models/catboost_model.cbm
2025-07-15 22:42:15 [INFO] pipeline - Forecast CatBoost criado para 7 dias
2025-07-15 22:42:15 [INFO] pipeline - Forecast salvo em data/models/catboost_forecast.csv
2025-07-15 22:42:15 [INFO] pipeline - ==== FIM DO TREINO CATBOOST ====
2025-07-15 23:06:02 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE RECONCILIAÇÃO ====
2025-07-15 23:06:02 [INFO] pipeline - ==== INÍCIO DA RECONCILIAÇÃO ====
2025-07-15 23:06:02 [INFO] pipeline - Lendo forecast LightGBM de data/models/ml_forecast.csv
2025-07-15 23:06:02 [INFO] pipeline - ML forecast: 39872 linhas
2025-07-15 23:06:02 [INFO] pipeline - Lendo forecast CatBoost de data/models/catboost_forecast.csv
2025-07-15 23:06:02 [INFO] pipeline - CatBoost forecast: 39872 linhas
2025-07-15 23:06:02 [INFO] pipeline - Lendo histórico processado de data/processed/vendas_processed.csv
2025-07-15 23:24:03 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE RECONCILIAÇÃO ====
2025-07-15 23:24:03 [INFO] pipeline - ==== INÍCIO DA RECONCILIAÇÃO ====
2025-07-15 23:24:03 [INFO] pipeline - Lendo forecast LightGBM de data/models/ml_forecast.csv
2025-07-15 23:24:03 [INFO] pipeline - ML forecast: 39872 linhas
2025-07-15 23:24:03 [INFO] pipeline - Lendo forecast CatBoost de data/models/catboost_forecast.csv
2025-07-15 23:24:03 [INFO] pipeline - CatBoost forecast: 39872 linhas
2025-07-15 23:24:03 [INFO] pipeline - Lendo histórico processado de data/processed/vendas_processed.csv
2025-07-15 23:26:23 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE RECONCILIAÇÃO ====
2025-07-15 23:26:23 [INFO] pipeline - ==== INÍCIO DA RECONCILIAÇÃO ====
2025-07-15 23:26:23 [INFO] pipeline - Lendo forecast LightGBM de data/models/ml_forecast.csv
2025-07-15 23:26:23 [INFO] pipeline - ML forecast: 39872 linhas
2025-07-15 23:26:23 [INFO] pipeline - Lendo forecast CatBoost de data/models/catboost_forecast.csv
2025-07-15 23:26:23 [INFO] pipeline - CatBoost forecast: 39872 linhas
2025-07-15 23:26:23 [INFO] pipeline - Lendo histórico processado de data/processed/vendas_processed.csv
2025-07-15 23:26:24 [INFO] pipeline - Histórico: 230704 linhas (arquivo: data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv)
2025-07-15 23:26:24 [INFO] pipeline - Criado campo 'reconciled' = média de lgbm_pred e cb_pred
2025-07-15 23:26:24 [INFO] pipeline - Computado resumo diário agregado
2025-07-15 23:26:24 [INFO] pipeline - Reconciled SKU-level salvo em data/models/reconciled_sku_forecast.csv
2025-07-15 23:26:24 [INFO] pipeline - Reconciled daily summary salvo em data/models/reconciled_daily_summary.csv
2025-07-15 23:26:24 [INFO] pipeline - ==== FIM DA RECONCILIAÇÃO ====
2025-07-15 23:32:29 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE AVALIAÇÃO ====
2025-07-15 23:32:29 [INFO] pipeline - ==== INÍCIO DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-15 23:32:29 [INFO] pipeline - ==== CARREGANDO DADOS PARA AVALIAÇÃO ====
2025-07-15 23:32:29 [INFO] pipeline - Lido data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv: 230704 linhas, 4 colunas
2025-07-15 23:32:29 [INFO] pipeline - Lido data/models/ml_forecast.csv: 39872 linhas, 3 colunas
2025-07-15 23:32:29 [INFO] pipeline - Lido data/models/catboost_forecast.csv: 39872 linhas, 3 colunas
2025-07-15 23:32:29 [INFO] pipeline - Lido data/models/reconciled_sku_forecast.csv: 39872 linhas, 6 colunas
2025-07-15 23:40:28 [INFO] pipeline - ==== INÍCIO DO TREINO LIGHTGBM ====
2025-07-15 23:40:28 [INFO] pipeline - Carregando features de data/features/vendas_features.csv
2025-07-15 23:40:29 [INFO] pipeline - Dados carregados: 230704 linhas, 14 colunas
2025-07-15 23:40:29 [INFO] pipeline - fold 1/5 — RMSE: 5.0482, MAE: 2.5093, MAPE: 14.66%, WMAPE: 21.59%, R²: 0.8944
2025-07-15 23:40:30 [INFO] pipeline - fold 2/5 — RMSE: 6.2112, MAE: 3.5017, MAPE: 17.01%, WMAPE: 19.73%, R²: 0.9062
2025-07-15 23:40:31 [INFO] pipeline - fold 3/5 — RMSE: 80.1813, MAE: 7.5134, MAPE: 15.59%, WMAPE: 37.46%, R²: 0.2152
2025-07-15 23:40:32 [INFO] pipeline - fold 4/5 — RMSE: 4.9465, MAE: 2.4113, MAPE: 14.83%, WMAPE: 21.47%, R²: 0.9025
2025-07-15 23:40:33 [INFO] pipeline - fold 5/5 — RMSE: 4.8540, MAE: 2.5403, MAPE: 15.32%, WMAPE: 21.36%, R²: 0.8858
2025-07-15 23:40:33 [INFO] pipeline - CV RMSE média: 20.2483  desvio: 33.5081
2025-07-15 23:40:33 [INFO] pipeline - Treinando LightGBM no dataset completo
2025-07-15 23:40:35 [INFO] pipeline - Modelo salvo em data/models/lgbm_model.pkl
2025-07-15 23:40:40 [INFO] pipeline - Forecast criado para 7 dias
2025-07-15 23:40:41 [INFO] pipeline - Forecast completo (in-sample + futuro) salvo em data/models/ml_forecast.csv
2025-07-15 23:40:41 [INFO] pipeline - ==== FIM DO TREINO LIGHTGBM ====
2025-07-15 23:41:16 [INFO] pipeline - ==== INÍCIO DO TREINO CATBOOST ====
2025-07-15 23:41:16 [INFO] pipeline - Lendo features de data/features/vendas_features.csv
2025-07-15 23:41:16 [INFO] pipeline - Dados carregados: 230704 linhas, 14 colunas (arquivo: data/features/vendas_features.csv/part-00000-5393d33c-7a86-4c4a-9088-fb736837fc97-c000.csv)
2025-07-15 23:41:17 [INFO] pipeline - fold 1/5 — RMSE: 5.1635, MAE: 2.6137, MAPE: 21.15%, WMAPE: 22.48%, R²: 0.8896
2025-07-15 23:41:17 [INFO] pipeline - fold 2/5 — RMSE: 6.2760, MAE: 3.5579, MAPE: 19.80%, WMAPE: 20.05%, R²: 0.9042
2025-07-15 23:41:18 [INFO] pipeline - fold 3/5 — RMSE: 80.3538, MAE: 7.6103, MAPE: 19.52%, WMAPE: 37.94%, R²: 0.2118
2025-07-15 23:41:19 [INFO] pipeline - fold 4/5 — RMSE: 5.2489, MAE: 2.6281, MAPE: 27.03%, WMAPE: 23.40%, R²: 0.8903
2025-07-15 23:41:20 [INFO] pipeline - fold 5/5 — RMSE: 5.1353, MAE: 2.7299, MAPE: 24.69%, WMAPE: 22.95%, R²: 0.8722
2025-07-15 23:41:20 [INFO] pipeline - CV RMSE média: 20.4355  desvio: 33.4987
2025-07-15 23:41:20 [INFO] pipeline - cross-validation concluído
2025-07-15 23:41:20 [INFO] pipeline - Treinando CatBoost no dataset completo
2025-07-15 23:41:23 [INFO] pipeline - Modelo salvo em data/models/catboost_model.cbm
2025-07-15 23:41:29 [INFO] pipeline - Forecast CatBoost criado para 7 dias
2025-07-15 23:41:29 [INFO] pipeline - Forecast completo (in-sample + futuro) salvo em data/models/catboost_forecast.csv
2025-07-15 23:41:29 [INFO] pipeline - ==== FIM DO TREINO CATBOOST ====
2025-07-15 23:43:51 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE RECONCILIAÇÃO ====
2025-07-15 23:43:51 [INFO] pipeline - ==== INÍCIO DA RECONCILIAÇÃO ====
2025-07-15 23:43:51 [INFO] pipeline - Lendo forecast LightGBM de data/models/ml_forecast.csv
2025-07-15 23:43:51 [INFO] pipeline - ML forecast: 270576 linhas
2025-07-15 23:43:51 [INFO] pipeline - Lendo forecast CatBoost de data/models/catboost_forecast.csv
2025-07-15 23:43:51 [INFO] pipeline - CatBoost forecast: 270576 linhas
2025-07-15 23:43:51 [INFO] pipeline - Lendo histórico processado de data/processed/vendas_processed.csv
2025-07-15 23:43:51 [INFO] pipeline - Histórico: 230704 linhas (arquivo: data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv)
2025-07-15 23:43:51 [INFO] pipeline - Criado campo 'reconciled' = média de lgbm_pred e cb_pred
2025-07-15 23:43:51 [INFO] pipeline - Computado resumo diário agregado
2025-07-15 23:43:53 [INFO] pipeline - Reconciled SKU-level salvo em data/models/reconciled_sku_forecast.csv
2025-07-15 23:43:53 [INFO] pipeline - Reconciled daily summary salvo em data/models/reconciled_daily_summary.csv
2025-07-15 23:43:53 [INFO] pipeline - ==== FIM DA RECONCILIAÇÃO ====
2025-07-15 23:45:05 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE AVALIAÇÃO ====
2025-07-15 23:45:05 [INFO] pipeline - ==== INÍCIO DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-15 23:45:05 [INFO] pipeline - ==== CARREGANDO DADOS PARA AVALIAÇÃO ====
2025-07-15 23:45:05 [INFO] pipeline - Lido data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv: 230704 linhas, 4 colunas
2025-07-15 23:45:05 [INFO] pipeline - Lido data/models/ml_forecast.csv: 270576 linhas, 3 colunas
2025-07-15 23:45:05 [INFO] pipeline - Lido data/models/catboost_forecast.csv: 270576 linhas, 3 colunas
2025-07-15 23:45:05 [INFO] pipeline - Lido data/models/reconciled_sku_forecast.csv: 270576 linhas, 6 colunas
2025-07-15 23:45:06 [INFO] pipeline - lgbm granular: {'rmse': 8.052946504521012, 'mae': 2.9464274121803675, 'r2': 0.9608634906875356, 'mape': np.float64(15.040836894894902), 'wmape': np.float64(19.28949079910145)}
2025-07-15 23:45:06 [INFO] pipeline - lgbm aggregate: {'rmse': 3055.653391462601, 'mae': 2079.37552849157, 'r2': 0.9611223900209676, 'mape': np.float64(5.408347088512779), 'wmape': np.float64(5.0745936580389985)}
2025-07-15 23:45:06 [INFO] pipeline - catboost granular: {'rmse': 7.164140513308316, 'mae': 3.112634275381672, 'r2': 0.9690257606836886, 'mape': np.float64(23.126169274792915), 'wmape': np.float64(20.377603727054627)}
2025-07-15 23:45:06 [INFO] pipeline - catboost aggregate: {'rmse': 3427.202005221296, 'mae': 2483.45320755273, 'r2': 0.9510930268266098, 'mape': np.float64(6.418479237027613), 'wmape': np.float64(6.060721463922327)}
2025-07-16 00:32:01 [INFO] pipeline - ==== INÍCIO FORECAST SKU=1234 ====
2025-07-16 00:32:01 [INFO] pipeline - Carregando LGBM de data/models/lgbm_model.pkl
2025-07-16 00:32:01 [INFO] pipeline - Carregando CatBoost de data/models/catboost_model.cbm
2025-07-16 00:32:39 [INFO] pipeline - ==== INÍCIO FORECAST SKU=1 ====
2025-07-16 00:32:40 [INFO] pipeline - Carregando LGBM de data/models/lgbm_model.pkl
2025-07-16 00:32:40 [INFO] pipeline - Carregando CatBoost de data/models/catboost_model.cbm
2025-07-16 00:39:57 [INFO] pipeline - ==== INÍCIO FORECAST SKU=12 ====
2025-07-16 00:39:57 [INFO] pipeline - Carregando LGBM de data/models/lgbm_model.pkl
2025-07-16 00:39:57 [INFO] pipeline - Carregando CatBoost de data/models/catboost_model.cbm
2025-07-16 00:45:34 [INFO] pipeline - ==== INÍCIO FORECAST SKU=12 ====
2025-07-16 00:45:35 [INFO] pipeline - Carregando LGBM de data/models/lgbm_model.pkl
2025-07-16 00:45:35 [INFO] pipeline - Carregando CatBoost de data/models/catboost_model.cbm
2025-07-16 00:45:35 [INFO] pipeline - Histórico SKU=12: 0 linhas
2025-07-16 00:50:21 [INFO] pipeline - ==== INÍCIO FORECAST SKU=12 ====
2025-07-16 00:50:21 [INFO] pipeline - Carregando LGBM de data/models/lgbm_model.pkl
2025-07-16 00:50:21 [INFO] pipeline - Carregando CatBoost de data/models/catboost_model.cbm
2025-07-16 00:50:21 [INFO] pipeline - Histórico SKU=12: 0 linhas (arquivo: data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv)
2025-07-16 00:50:21 [INFO] pipeline - Features SKU=12: 0 linhas (arquivo: data/features/vendas_features.csv/part-00000-5393d33c-7a86-4c4a-9088-fb736837fc97-c000.csv)
2025-07-16 00:51:32 [INFO] pipeline - ==== INÍCIO FORECAST SKU=12 ====
2025-07-16 00:51:33 [INFO] pipeline - Carregando LGBM de data/models/lgbm_model.pkl
2025-07-16 00:51:33 [INFO] pipeline - Carregando CatBoost de data/models/catboost_model.cbm
2025-07-16 00:51:33 [INFO] pipeline - Histórico SKU=12: 0 linhas (arquivo: data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv)
2025-07-16 00:51:33 [INFO] pipeline - Features SKU=12: 0 linhas (arquivo: data/features/vendas_features.csv/part-00000-5393d33c-7a86-4c4a-9088-fb736837fc97-c000.csv)
2025-07-16 00:54:40 [INFO] pipeline - ==== INÍCIO FORECAST SKU=12 ====
2025-07-16 00:54:40 [INFO] pipeline - Carregando LGBM de data/models/lgbm_model.pkl
2025-07-16 00:54:40 [INFO] pipeline - Carregando CatBoost de data/models/catboost_model.cbm
2025-07-16 00:54:41 [INFO] pipeline - Histórico SKU=12: 86 linhas (arquivo: data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv)
2025-07-16 00:54:41 [INFO] pipeline - Features SKU=12: 86 linhas (arquivo: data/features/vendas_features.csv/part-00000-5393d33c-7a86-4c4a-9088-fb736837fc97-c000.csv)
2025-07-16 00:54:41 [INFO] pipeline - Gerado forecast SKU=12 com 93 linhas
2025-07-16 00:54:41 [INFO] pipeline - Forecast SKU salvo em data/models/forecast_sku_12.csv
2025-07-16 00:54:41 [INFO] pipeline - ==== FIM FORECAST SKU=12 ====
2025-07-16 00:56:43 [INFO] pipeline - ==== INÍCIO FORECAST SKU=12 ====
2025-07-16 00:56:43 [INFO] pipeline - Carregando LGBM de data/models/lgbm_model.pkl
2025-07-16 00:56:43 [INFO] pipeline - Carregando CatBoost de data/models/catboost_model.cbm
2025-07-16 00:56:43 [INFO] pipeline - Histórico SKU=12: 0 linhas (arquivo: data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv)
2025-07-16 00:56:43 [INFO] pipeline - Features SKU=12: 0 linhas (arquivo: data/features/vendas_features.csv/part-00000-5393d33c-7a86-4c4a-9088-fb736837fc97-c000.csv)
2025-07-16 00:57:09 [INFO] pipeline - ==== INÍCIO FORECAST SKU=12 ====
2025-07-16 00:57:10 [INFO] pipeline - Carregando LGBM de data/models/lgbm_model.pkl
2025-07-16 00:57:10 [INFO] pipeline - Carregando CatBoost de data/models/catboost_model.cbm
2025-07-16 00:57:10 [INFO] pipeline - Histórico SKU=12: 86 linhas (arquivo: data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv)
2025-07-16 00:57:10 [INFO] pipeline - Features SKU=12: 86 linhas (arquivo: data/features/vendas_features.csv/part-00000-5393d33c-7a86-4c4a-9088-fb736837fc97-c000.csv)
2025-07-16 00:57:10 [INFO] pipeline - Gerado forecast SKU=12 com 93 linhas
2025-07-16 00:57:10 [INFO] pipeline - Forecast SKU salvo em data/models/forecast_sku_12.csv
2025-07-16 00:57:10 [INFO] pipeline - ==== FIM FORECAST SKU=12 ====
2025-07-16 00:57:13 [INFO] pipeline - ==== INÍCIO FORECAST SKU=1 ====
2025-07-16 00:57:14 [INFO] pipeline - Carregando LGBM de data/models/lgbm_model.pkl
2025-07-16 00:57:14 [INFO] pipeline - Carregando CatBoost de data/models/catboost_model.cbm
2025-07-16 00:57:14 [INFO] pipeline - Histórico SKU=1: 84 linhas (arquivo: data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv)
2025-07-16 00:57:14 [INFO] pipeline - Features SKU=1: 84 linhas (arquivo: data/features/vendas_features.csv/part-00000-5393d33c-7a86-4c4a-9088-fb736837fc97-c000.csv)
2025-07-16 00:57:14 [INFO] pipeline - Gerado forecast SKU=1 com 91 linhas
2025-07-16 00:57:14 [INFO] pipeline - Forecast SKU salvo em data/models/forecast_sku_1.csv
2025-07-16 00:57:14 [INFO] pipeline - ==== FIM FORECAST SKU=1 ====
2025-07-16 01:23:59 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE AVALIAÇÃO ====
2025-07-16 01:23:59 [INFO] pipeline - ==== INÍCIO DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-16 01:23:59 [INFO] pipeline - ==== CARREGANDO DADOS PARA AVALIAÇÃO ====
2025-07-16 01:23:59 [INFO] pipeline - Lido data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv: 230704 linhas, 4 colunas
2025-07-16 01:23:59 [INFO] pipeline - Lido data/models/ml_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:23:59 [INFO] pipeline - Lido data/models/catboost_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:23:59 [INFO] pipeline - Lido data/models/reconciled_sku_forecast.csv: 270576 linhas, 6 colunas
2025-07-16 01:23:59 [INFO] pipeline - lgbm granular: {'rmse': 8.052946504521012, 'mae': 2.9464274121803675, 'r2': 0.9608634906875356, 'mape': np.float64(15.040836894894902), 'wmape': np.float64(19.28949079910145)}
2025-07-16 01:23:59 [INFO] pipeline - lgbm aggregate: {'rmse': 3055.653391462601, 'mae': 2079.37552849157, 'r2': 0.9611223900209676, 'mape': np.float64(5.408347088512779), 'wmape': np.float64(5.0745936580389985)}
2025-07-16 01:23:59 [INFO] pipeline - catboost granular: {'rmse': 7.164140513308316, 'mae': 3.112634275381672, 'r2': 0.9690257606836886, 'mape': np.float64(23.126169274792915), 'wmape': np.float64(20.377603727054627)}
2025-07-16 01:23:59 [INFO] pipeline - catboost aggregate: {'rmse': 3427.202005221296, 'mae': 2483.45320755273, 'r2': 0.9510930268266098, 'mape': np.float64(6.418479237027613), 'wmape': np.float64(6.060721463922327)}
2025-07-16 01:27:20 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE AVALIAÇÃO ====
2025-07-16 01:27:20 [INFO] pipeline - ==== INÍCIO DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-16 01:27:20 [INFO] pipeline - ==== CARREGANDO DADOS PARA AVALIAÇÃO ====
2025-07-16 01:27:20 [INFO] pipeline - Lido data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv: 230704 linhas, 4 colunas
2025-07-16 01:27:20 [INFO] pipeline - Lido data/models/ml_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:27:20 [INFO] pipeline - Lido data/models/catboost_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:27:20 [INFO] pipeline - Lido data/models/reconciled_sku_forecast.csv: 270576 linhas, 6 colunas
2025-07-16 01:32:01 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE AVALIAÇÃO ====
2025-07-16 01:32:01 [INFO] pipeline - ==== INÍCIO DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-16 01:32:01 [INFO] pipeline - ==== CARREGANDO DADOS PARA AVALIAÇÃO ====
2025-07-16 01:32:01 [INFO] pipeline - Lido data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv: 230704 linhas, 4 colunas
2025-07-16 01:32:01 [INFO] pipeline - Lido data/models/ml_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:32:01 [INFO] pipeline - Lido data/models/catboost_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:32:01 [INFO] pipeline - Lido data/models/reconciled_sku_forecast.csv: 270576 linhas, 6 colunas
2025-07-16 01:32:01 [INFO] pipeline - lgbm granular: {'rmse': 8.052946504521012, 'mae': 2.9464274121803675, 'r2': 0.9608634906875356, 'mape': np.float64(15.040836894894902), 'wmape': np.float64(19.28949079910145)}
2025-07-16 01:32:01 [INFO] pipeline - lgbm aggregate: {'rmse': 3055.653391462601, 'mae': 2079.37552849157, 'r2': 0.9611223900209676, 'mape': np.float64(5.408347088512779), 'wmape': np.float64(5.0745936580389985)}
2025-07-16 01:32:01 [INFO] pipeline - catboost granular: {'rmse': 7.164140513308316, 'mae': 3.112634275381672, 'r2': 0.9690257606836886, 'mape': np.float64(23.126169274792915), 'wmape': np.float64(20.377603727054627)}
2025-07-16 01:32:01 [INFO] pipeline - catboost aggregate: {'rmse': 3427.202005221296, 'mae': 2483.45320755273, 'r2': 0.9510930268266098, 'mape': np.float64(6.418479237027613), 'wmape': np.float64(6.060721463922327)}
2025-07-16 01:34:13 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE AVALIAÇÃO ====
2025-07-16 01:34:13 [INFO] pipeline - ==== INÍCIO DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-16 01:34:13 [INFO] pipeline - ==== CARREGANDO DADOS PARA AVALIAÇÃO ====
2025-07-16 01:34:13 [INFO] pipeline - Lido data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv: 230704 linhas, 4 colunas
2025-07-16 01:34:13 [INFO] pipeline - Lido data/models/ml_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:34:13 [INFO] pipeline - Lido data/models/catboost_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:34:13 [INFO] pipeline - Lido data/models/reconciled_sku_forecast.csv: 270576 linhas, 6 colunas
2025-07-16 01:34:13 [INFO] pipeline - lgbm granular: {'rmse': 8.052946504521012, 'mae': 2.9464274121803675, 'r2': 0.9608634906875356, 'mape': np.float64(15.040836894894902), 'wmape': np.float64(19.28949079910145)}
2025-07-16 01:34:13 [INFO] pipeline - lgbm aggregate: {'rmse': 3055.653391462601, 'mae': 2079.37552849157, 'r2': 0.9611223900209676, 'mape': np.float64(5.408347088512779), 'wmape': np.float64(5.0745936580389985)}
2025-07-16 01:34:13 [INFO] pipeline - catboost granular: {'rmse': 7.164140513308316, 'mae': 3.112634275381672, 'r2': 0.9690257606836886, 'mape': np.float64(23.126169274792915), 'wmape': np.float64(20.377603727054627)}
2025-07-16 01:34:13 [INFO] pipeline - catboost aggregate: {'rmse': 3427.202005221296, 'mae': 2483.45320755273, 'r2': 0.9510930268266098, 'mape': np.float64(6.418479237027613), 'wmape': np.float64(6.060721463922327)}
2025-07-16 01:39:54 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE AVALIAÇÃO ====
2025-07-16 01:39:54 [INFO] pipeline - ==== INÍCIO DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-16 01:39:54 [INFO] pipeline - ==== CARREGANDO DADOS PARA AVALIAÇÃO ====
2025-07-16 01:39:54 [INFO] pipeline - Lido data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv: 230704 linhas, 4 colunas
2025-07-16 01:39:54 [INFO] pipeline - Lido data/models/ml_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:39:54 [INFO] pipeline - Lido data/models/catboost_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:39:54 [INFO] pipeline - Lido data/models/reconciled_sku_forecast.csv: 270576 linhas, 6 colunas
2025-07-16 01:39:54 [INFO] pipeline - lgbm granular: {'rmse': 8.052946504521012, 'mae': 2.9464274121803675, 'r2': 0.9608634906875356, 'mape': np.float64(15.040836894894902), 'wmape': np.float64(19.28949079910145)}
2025-07-16 01:39:54 [INFO] pipeline - lgbm aggregate: {'rmse': 3055.653391462601, 'mae': 2079.37552849157, 'r2': 0.9611223900209676, 'mape': np.float64(5.408347088512779), 'wmape': np.float64(5.0745936580389985)}
2025-07-16 01:39:54 [INFO] pipeline - catboost granular: {'rmse': 7.164140513308316, 'mae': 3.112634275381672, 'r2': 0.9690257606836886, 'mape': np.float64(23.126169274792915), 'wmape': np.float64(20.377603727054627)}
2025-07-16 01:39:54 [INFO] pipeline - catboost aggregate: {'rmse': 3427.202005221296, 'mae': 2483.45320755273, 'r2': 0.9510930268266098, 'mape': np.float64(6.418479237027613), 'wmape': np.float64(6.060721463922327)}
2025-07-16 01:46:18 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE AVALIAÇÃO ====
2025-07-16 01:46:18 [INFO] pipeline - ==== INÍCIO DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-16 01:46:18 [INFO] pipeline - ==== CARREGANDO DADOS PARA AVALIAÇÃO ====
2025-07-16 01:46:18 [INFO] pipeline - Lido data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv: 230704 linhas, 4 colunas
2025-07-16 01:46:18 [INFO] pipeline - Lido data/models/ml_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:46:18 [INFO] pipeline - Lido data/models/catboost_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:46:19 [INFO] pipeline - Lido data/models/reconciled_sku_forecast.csv: 270576 linhas, 6 colunas
2025-07-16 01:46:19 [INFO] pipeline - lgbm granular: {'rmse': 8.052946504521012, 'mae': 2.9464274121803675, 'r2': 0.9608634906875356, 'mape': np.float64(15.040836894894902), 'wmape': np.float64(19.28949079910145)}
2025-07-16 01:46:19 [INFO] pipeline - lgbm aggregate: {'rmse': 3055.653391462601, 'mae': 2079.37552849157, 'r2': 0.9611223900209676, 'mape': np.float64(5.408347088512779), 'wmape': np.float64(5.0745936580389985)}
2025-07-16 01:46:19 [INFO] pipeline - catboost granular: {'rmse': 7.164140513308316, 'mae': 3.112634275381672, 'r2': 0.9690257606836886, 'mape': np.float64(23.126169274792915), 'wmape': np.float64(20.377603727054627)}
2025-07-16 01:46:19 [INFO] pipeline - catboost aggregate: {'rmse': 3427.202005221296, 'mae': 2483.45320755273, 'r2': 0.9510930268266098, 'mape': np.float64(6.418479237027613), 'wmape': np.float64(6.060721463922327)}
2025-07-16 01:50:13 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE AVALIAÇÃO ====
2025-07-16 01:50:13 [INFO] pipeline - ==== INÍCIO DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-16 01:50:13 [INFO] pipeline - ==== CARREGANDO DADOS PARA AVALIAÇÃO ====
2025-07-16 01:50:13 [INFO] pipeline - Lido data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv: 230704 linhas, 4 colunas
2025-07-16 01:50:13 [INFO] pipeline - Lido data/models/ml_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:50:13 [INFO] pipeline - Lido data/models/catboost_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:50:13 [INFO] pipeline - Lido data/models/reconciled_sku_forecast.csv: 270576 linhas, 6 colunas
2025-07-16 01:50:13 [INFO] pipeline - lgbm granular: {'rmse': 8.052946504521012, 'mae': 2.9464274121803675, 'r2': 0.9608634906875356, 'mape': np.float64(15.040836894894902), 'wmape': np.float64(19.28949079910145)}
2025-07-16 01:50:13 [INFO] pipeline - lgbm aggregate: {'rmse': 3055.653391462601, 'mae': 2079.37552849157, 'r2': 0.9611223900209676, 'mape': np.float64(5.408347088512779), 'wmape': np.float64(5.0745936580389985)}
2025-07-16 01:50:13 [INFO] pipeline - catboost granular: {'rmse': 7.164140513308316, 'mae': 3.112634275381672, 'r2': 0.9690257606836886, 'mape': np.float64(23.126169274792915), 'wmape': np.float64(20.377603727054627)}
2025-07-16 01:50:13 [INFO] pipeline - catboost aggregate: {'rmse': 3427.202005221296, 'mae': 2483.45320755273, 'r2': 0.9510930268266098, 'mape': np.float64(6.418479237027613), 'wmape': np.float64(6.060721463922327)}
2025-07-16 01:52:06 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE AVALIAÇÃO ====
2025-07-16 01:52:06 [INFO] pipeline - ==== INÍCIO DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-16 01:52:06 [INFO] pipeline - ==== CARREGANDO DADOS PARA AVALIAÇÃO ====
2025-07-16 01:52:06 [INFO] pipeline - Lido data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv: 230704 linhas, 4 colunas
2025-07-16 01:52:06 [INFO] pipeline - [DEBUG] colunas de hist: ['sku', 'data', 'venda', 'is_imputed']
2025-07-16 01:52:06 [INFO] pipeline - Lido data/models/ml_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:52:06 [INFO] pipeline - Lido data/models/catboost_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:52:06 [INFO] pipeline - Lido data/models/reconciled_sku_forecast.csv: 270576 linhas, 6 colunas
2025-07-16 01:52:06 [INFO] pipeline - lgbm granular: {'rmse': 8.052946504521012, 'mae': 2.9464274121803675, 'r2': 0.9608634906875356, 'mape': np.float64(15.040836894894902), 'wmape': np.float64(19.28949079910145)}
2025-07-16 01:52:06 [INFO] pipeline - lgbm aggregate: {'rmse': 3055.653391462601, 'mae': 2079.37552849157, 'r2': 0.9611223900209676, 'mape': np.float64(5.408347088512779), 'wmape': np.float64(5.0745936580389985)}
2025-07-16 01:52:06 [INFO] pipeline - catboost granular: {'rmse': 7.164140513308316, 'mae': 3.112634275381672, 'r2': 0.9690257606836886, 'mape': np.float64(23.126169274792915), 'wmape': np.float64(20.377603727054627)}
2025-07-16 01:52:06 [INFO] pipeline - catboost aggregate: {'rmse': 3427.202005221296, 'mae': 2483.45320755273, 'r2': 0.9510930268266098, 'mape': np.float64(6.418479237027613), 'wmape': np.float64(6.060721463922327)}
2025-07-16 01:54:19 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE AVALIAÇÃO ====
2025-07-16 01:54:19 [INFO] pipeline - ==== INÍCIO DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-16 01:54:19 [INFO] pipeline - ==== CARREGANDO DADOS PARA AVALIAÇÃO ====
2025-07-16 01:54:19 [INFO] pipeline - Lido data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv: 230704 linhas, 4 colunas
2025-07-16 01:54:19 [INFO] pipeline - Lido data/models/ml_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:54:19 [INFO] pipeline - Lido data/models/catboost_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:54:19 [INFO] pipeline - Lido data/models/reconciled_sku_forecast.csv: 270576 linhas, 6 colunas
2025-07-16 01:54:19 [INFO] pipeline - [DEBUG] colunas originais de hist: ['sku', 'data', 'venda', 'is_imputed']
2025-07-16 01:54:19 [INFO] pipeline - lgbm granular: {'rmse': 8.052946504521012, 'mae': 2.9464274121803675, 'r2': 0.9608634906875356, 'mape': np.float64(15.040836894894902), 'wmape': np.float64(19.28949079910145)}
2025-07-16 01:54:19 [INFO] pipeline - lgbm aggregate: {'rmse': 3055.653391462601, 'mae': 2079.37552849157, 'r2': 0.9611223900209676, 'mape': np.float64(5.408347088512779), 'wmape': np.float64(5.0745936580389985)}
2025-07-16 01:54:19 [INFO] pipeline - catboost granular: {'rmse': 7.164140513308316, 'mae': 3.112634275381672, 'r2': 0.9690257606836886, 'mape': np.float64(23.126169274792915), 'wmape': np.float64(20.377603727054627)}
2025-07-16 01:54:19 [INFO] pipeline - catboost aggregate: {'rmse': 3427.202005221296, 'mae': 2483.45320755273, 'r2': 0.9510930268266098, 'mape': np.float64(6.418479237027613), 'wmape': np.float64(6.060721463922327)}
2025-07-16 01:54:53 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE AVALIAÇÃO ====
2025-07-16 01:54:53 [INFO] pipeline - ==== INÍCIO DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-16 01:54:53 [INFO] pipeline - ==== CARREGANDO DADOS PARA AVALIAÇÃO ====
2025-07-16 01:54:53 [INFO] pipeline - Lido data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv: 230704 linhas, 4 colunas
2025-07-16 01:54:53 [INFO] pipeline - Lido data/models/ml_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:54:53 [INFO] pipeline - Lido data/models/catboost_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 01:54:53 [INFO] pipeline - Lido data/models/reconciled_sku_forecast.csv: 270576 linhas, 6 colunas
2025-07-16 01:54:53 [INFO] pipeline - [DEBUG] colunas originais de hist: ['sku', 'data', 'venda', 'is_imputed']
2025-07-16 01:54:53 [INFO] pipeline - lgbm granular: {'rmse': 8.052946504521012, 'mae': 2.9464274121803675, 'r2': 0.9608634906875356, 'mape': np.float64(15.040836894894902), 'wmape': np.float64(19.28949079910145)}
2025-07-16 01:54:53 [INFO] pipeline - lgbm aggregate: {'rmse': 3055.653391462601, 'mae': 2079.37552849157, 'r2': 0.9611223900209676, 'mape': np.float64(5.408347088512779), 'wmape': np.float64(5.0745936580389985)}
2025-07-16 01:54:53 [INFO] pipeline - catboost granular: {'rmse': 7.164140513308316, 'mae': 3.112634275381672, 'r2': 0.9690257606836886, 'mape': np.float64(23.126169274792915), 'wmape': np.float64(20.377603727054627)}
2025-07-16 01:54:53 [INFO] pipeline - catboost aggregate: {'rmse': 3427.202005221296, 'mae': 2483.45320755273, 'r2': 0.9510930268266098, 'mape': np.float64(6.418479237027613), 'wmape': np.float64(6.060721463922327)}
2025-07-16 02:04:43 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE AVALIAÇÃO ====
2025-07-16 02:04:43 [INFO] pipeline - ==== INÍCIO DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-16 02:04:43 [INFO] pipeline - ==== CARREGANDO DADOS PARA AVALIAÇÃO ====
2025-07-16 02:04:43 [INFO] pipeline - Lido data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv: 230704 linhas, 4 colunas
2025-07-16 02:04:43 [INFO] pipeline - Lido data/models/ml_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 02:04:43 [INFO] pipeline - Lido data/models/catboost_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 02:04:43 [INFO] pipeline - Lido data/models/reconciled_sku_forecast.csv: 270576 linhas, 6 colunas
2025-07-16 02:04:43 [INFO] pipeline - [DEBUG] colunas originais de hist: ['sku', 'data', 'venda', 'is_imputed']
2025-07-16 02:04:43 [INFO] pipeline - lgbm granular: {'rmse': 8.052946504521012, 'mae': 2.9464274121803675, 'r2': 0.9608634906875356, 'mape': np.float64(15.040836894894902), 'wmape': np.float64(19.28949079910145)}
2025-07-16 02:04:43 [INFO] pipeline - lgbm aggregate: {'rmse': 3055.653391462601, 'mae': 2079.37552849157, 'r2': 0.9611223900209676, 'mape': np.float64(5.408347088512779), 'wmape': np.float64(5.0745936580389985)}
2025-07-16 02:04:44 [INFO] pipeline - catboost granular: {'rmse': 7.164140513308316, 'mae': 3.112634275381672, 'r2': 0.9690257606836886, 'mape': np.float64(23.126169274792915), 'wmape': np.float64(20.377603727054627)}
2025-07-16 02:04:44 [INFO] pipeline - catboost aggregate: {'rmse': 3427.202005221296, 'mae': 2483.45320755273, 'r2': 0.9510930268266098, 'mape': np.float64(6.418479237027613), 'wmape': np.float64(6.060721463922327)}
2025-07-16 02:12:08 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE AVALIAÇÃO ====
2025-07-16 02:12:08 [INFO] pipeline - ==== INÍCIO DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-16 02:12:08 [INFO] pipeline - ==== CARREGANDO DADOS PARA AVALIAÇÃO ====
2025-07-16 02:12:08 [INFO] pipeline - Lido data/processed/vendas_processed.csv/part-00000-dcc4e540-e7c2-4f4c-aa52-6d9164209be2-c000.csv: 230704 linhas, 4 colunas
2025-07-16 02:12:08 [INFO] pipeline - Lido data/models/ml_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 02:12:08 [INFO] pipeline - Lido data/models/catboost_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 02:12:08 [INFO] pipeline - Lido data/models/reconciled_sku_forecast.csv: 270576 linhas, 6 colunas
2025-07-16 02:12:08 [INFO] pipeline - [DEBUG] colunas originais de hist: ['sku', 'data', 'venda', 'is_imputed']
2025-07-16 02:12:08 [INFO] pipeline - lgbm granular: {'rmse': 8.052946504521012, 'mae': 2.9464274121803675, 'r2': 0.9608634906875356, 'mape': np.float64(15.040836894894902), 'wmape': np.float64(19.28949079910145)}
2025-07-16 02:12:08 [INFO] pipeline - lgbm aggregate: {'rmse': 3055.653391462601, 'mae': 2079.37552849157, 'r2': 0.9611223900209676, 'mape': np.float64(5.408347088512779), 'wmape': np.float64(5.0745936580389985)}
2025-07-16 02:12:08 [INFO] pipeline - catboost granular: {'rmse': 7.164140513308316, 'mae': 3.112634275381672, 'r2': 0.9690257606836886, 'mape': np.float64(23.126169274792915), 'wmape': np.float64(20.377603727054627)}
2025-07-16 02:12:08 [INFO] pipeline - catboost aggregate: {'rmse': 3427.202005221296, 'mae': 2483.45320755273, 'r2': 0.9510930268266098, 'mape': np.float64(6.418479237027613), 'wmape': np.float64(6.060721463922327)}
2025-07-16 02:18:22 INFO configuração de logging concluída
2025-07-16 02:18:22 INFO ==== INÍCIO DA ETAPA DE INGESTÃO ====
2025-07-16 02:18:28 INFO SparkSession com suporte a Delta iniciada
2025-07-16 02:18:33 INFO raw data carregada: 135226 linhas, 3 colunas
2025-07-16 02:18:34 INFO interim CSV salvo em data/interim/vendas_interim.csv
2025-07-16 02:18:41 INFO interim Delta salvo em data/interim/vendas_interim.delta
2025-07-16 02:18:41 INFO ==== FIM DA ETAPA DE INGESTÃO ====
2025-07-16 02:18:41 INFO ingestão concluída com sucesso
2025-07-16 02:18:41 INFO SparkSession finalizada
2025-07-16 02:18:41 INFO Closing down clientserver connection
2025-07-16 02:18:51 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE PREPROCESSAMENTO ====
2025-07-16 02:18:58 [INFO] pipeline - SparkSession com suporte a Delta iniciada
2025-07-16 02:18:58 [INFO] pipeline - ==== INÍCIO DA ETAPA DE PREPROCESSAMENTO ====
2025-07-16 02:18:58 [INFO] pipeline - lendo Delta de entrada em data/interim/vendas_interim.delta
2025-07-16 02:19:05 [INFO] pipeline - dados brutos carregados: 135226 linhas
2025-07-16 02:19:05 [INFO] pipeline - agrupadas duplicatas por sku+data
2025-07-16 02:19:05 [INFO] pipeline - gerada malha completa de datas por SKU
2025-07-16 02:19:06 [INFO] pipeline - marcado campo is_imputed
2025-07-16 02:19:06 [INFO] pipeline - preenchidos valores nulos de venda com zero
2025-07-16 02:19:06 [INFO] pipeline - ordenado por sku e data
2025-07-16 02:19:10 [INFO] pipeline - CSV processado salvo em data/processed/vendas_processed.csv
2025-07-16 02:19:15 [INFO] pipeline - Delta processado salvo em data/processed/vendas_processed.delta
2025-07-16 02:19:15 [INFO] pipeline - ==== FIM DA ETAPA DE PREPROCESSAMENTO ====
2025-07-16 02:19:16 [INFO] pipeline - SparkSession finalizada
2025-07-16 02:19:16 [INFO] py4j.clientserver - Closing down clientserver connection
2025-07-16 02:19:54 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE FEATURE ENGINEERING ====
2025-07-16 02:20:01 [INFO] pipeline - SparkSession com suporte a Delta iniciada para features
2025-07-16 02:20:01 [INFO] pipeline - ==== INÍCIO DA FEATURE ENGINEERING ====
2025-07-16 02:20:01 [INFO] pipeline - Features: lendo Delta de entrada em data/processed/vendas_processed.delta
2025-07-16 02:20:08 [INFO] pipeline - Features: dados brutos carregados (230704 linhas)
2025-07-16 02:20:08 [INFO] pipeline - Features: flag de imputação criado
2025-07-16 02:20:08 [INFO] pipeline - Features: lags [1, 7, 14] criados
2025-07-16 02:20:08 [INFO] pipeline - Features: rolling windows [7, 14, 30] criados
2025-07-16 02:20:08 [INFO] pipeline - Features: variáveis de calendário criadas
2025-07-16 02:20:12 [INFO] pipeline - Features: CSV salvo em data/features/vendas_features.csv
2025-07-16 02:20:16 [INFO] pipeline - Features: Delta salvo em data/features/vendas_features.delta
2025-07-16 02:20:16 [INFO] pipeline - ==== FIM DA FEATURE ENGINEERING ====
2025-07-16 02:20:16 [INFO] pipeline - SparkSession finalizada
2025-07-16 02:20:16 [INFO] py4j.clientserver - Closing down clientserver connection
2025-07-16 02:20:28 [INFO] pipeline - ==== INÍCIO DO TREINO LIGHTGBM ====
2025-07-16 02:20:28 [INFO] pipeline - Carregando features de data/features/vendas_features.csv
2025-07-16 02:20:28 [INFO] pipeline - Dados carregados: 230704 linhas, 14 colunas
2025-07-16 02:20:29 [INFO] pipeline - fold 1/5 — RMSE: 5.0482, MAE: 2.5093, MAPE: 14.66%, WMAPE: 21.59%, R²: 0.8944
2025-07-16 02:20:30 [INFO] pipeline - fold 2/5 — RMSE: 6.2112, MAE: 3.5017, MAPE: 17.01%, WMAPE: 19.73%, R²: 0.9062
2025-07-16 02:20:31 [INFO] pipeline - fold 3/5 — RMSE: 80.1813, MAE: 7.5134, MAPE: 15.59%, WMAPE: 37.46%, R²: 0.2152
2025-07-16 02:20:32 [INFO] pipeline - fold 4/5 — RMSE: 4.9465, MAE: 2.4113, MAPE: 14.83%, WMAPE: 21.47%, R²: 0.9025
2025-07-16 02:20:34 [INFO] pipeline - fold 5/5 — RMSE: 4.8540, MAE: 2.5403, MAPE: 15.32%, WMAPE: 21.36%, R²: 0.8858
2025-07-16 02:20:34 [INFO] pipeline - CV RMSE média: 20.2483  desvio: 33.5081
2025-07-16 02:20:34 [INFO] pipeline - Treinando LightGBM no dataset completo
2025-07-16 02:20:35 [INFO] pipeline - Modelo salvo em data/models/lgbm_model.pkl
2025-07-16 02:20:40 [INFO] pipeline - Forecast criado para 7 dias
2025-07-16 02:20:41 [INFO] pipeline - Forecast completo (in-sample + futuro) salvo em data/models/ml_forecast.csv
2025-07-16 02:20:41 [INFO] pipeline - ==== FIM DO TREINO LIGHTGBM ====
2025-07-16 02:20:50 [INFO] pipeline - ==== INÍCIO DO TREINO CATBOOST ====
2025-07-16 02:20:50 [INFO] pipeline - Lendo features de data/features/vendas_features.csv
2025-07-16 02:20:50 [INFO] pipeline - Dados carregados: 230704 linhas, 14 colunas (arquivo: data/features/vendas_features.csv/part-00000-32adba8c-be86-4f64-aeed-cea33669a4a5-c000.csv)
2025-07-16 02:20:50 [INFO] pipeline - fold 1/5 — RMSE: 5.1635, MAE: 2.6137, MAPE: 21.15%, WMAPE: 22.48%, R²: 0.8896
2025-07-16 02:20:51 [INFO] pipeline - fold 2/5 — RMSE: 6.2760, MAE: 3.5579, MAPE: 19.80%, WMAPE: 20.05%, R²: 0.9042
2025-07-16 02:20:52 [INFO] pipeline - fold 3/5 — RMSE: 80.3538, MAE: 7.6103, MAPE: 19.52%, WMAPE: 37.94%, R²: 0.2118
2025-07-16 02:20:53 [INFO] pipeline - fold 4/5 — RMSE: 5.2489, MAE: 2.6281, MAPE: 27.03%, WMAPE: 23.40%, R²: 0.8903
2025-07-16 02:20:54 [INFO] pipeline - fold 5/5 — RMSE: 5.1353, MAE: 2.7299, MAPE: 24.69%, WMAPE: 22.95%, R²: 0.8722
2025-07-16 02:20:54 [INFO] pipeline - CV RMSE média: 20.4355  desvio: 33.4987
2025-07-16 02:20:54 [INFO] pipeline - cross-validation concluído
2025-07-16 02:20:54 [INFO] pipeline - Treinando CatBoost no dataset completo
2025-07-16 02:20:57 [INFO] pipeline - Modelo salvo em data/models/catboost_model.cbm
2025-07-16 02:21:02 [INFO] pipeline - Forecast CatBoost criado para 7 dias
2025-07-16 02:21:02 [INFO] pipeline - Forecast completo (in-sample + futuro) salvo em data/models/catboost_forecast.csv
2025-07-16 02:21:02 [INFO] pipeline - ==== FIM DO TREINO CATBOOST ====
2025-07-16 02:21:10 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE RECONCILIAÇÃO ====
2025-07-16 02:21:10 [INFO] pipeline - ==== INÍCIO DA RECONCILIAÇÃO ====
2025-07-16 02:21:10 [INFO] pipeline - Lendo forecast LightGBM de data/models/ml_forecast.csv
2025-07-16 02:21:10 [INFO] pipeline - ML forecast: 270576 linhas
2025-07-16 02:21:10 [INFO] pipeline - Lendo forecast CatBoost de data/models/catboost_forecast.csv
2025-07-16 02:21:10 [INFO] pipeline - CatBoost forecast: 270576 linhas
2025-07-16 02:21:10 [INFO] pipeline - Lendo histórico processado de data/processed/vendas_processed.csv
2025-07-16 02:21:10 [INFO] pipeline - Histórico: 230704 linhas (arquivo: data/processed/vendas_processed.csv/part-00000-5b0157c9-3230-417a-8d86-a7676a55ce7c-c000.csv)
2025-07-16 02:21:10 [INFO] pipeline - Criado campo 'reconciled' = média de lgbm_pred e cb_pred
2025-07-16 02:21:10 [INFO] pipeline - Computado resumo diário agregado
2025-07-16 02:21:11 [INFO] pipeline - Reconciled SKU-level salvo em data/models/reconciled_sku_forecast.csv
2025-07-16 02:21:11 [INFO] pipeline - Reconciled daily summary salvo em data/models/reconciled_daily_summary.csv
2025-07-16 02:21:11 [INFO] pipeline - ==== FIM DA RECONCILIAÇÃO ====
2025-07-16 02:21:18 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE AVALIAÇÃO ====
2025-07-16 02:21:18 [INFO] pipeline - ==== INÍCIO DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-16 02:21:18 [INFO] pipeline - ==== CARREGANDO DADOS PARA AVALIAÇÃO ====
2025-07-16 02:21:18 [INFO] pipeline - Lido data/processed/vendas_processed.csv/part-00000-5b0157c9-3230-417a-8d86-a7676a55ce7c-c000.csv: 230704 linhas, 4 colunas
2025-07-16 02:21:18 [INFO] pipeline - Lido data/models/ml_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 02:21:18 [INFO] pipeline - Lido data/models/catboost_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 02:21:18 [INFO] pipeline - Lido data/models/reconciled_sku_forecast.csv: 270576 linhas, 6 colunas
2025-07-16 02:21:18 [INFO] pipeline - [DEBUG] colunas originais de hist: ['sku', 'data', 'venda', 'is_imputed']
2025-07-16 02:21:18 [INFO] pipeline - lgbm granular: {'rmse': 8.052946504521012, 'mae': 2.9464274121803675, 'r2': 0.9608634906875356, 'mape': np.float64(15.040836894894902), 'wmape': np.float64(19.28949079910145)}
2025-07-16 02:21:18 [INFO] pipeline - lgbm aggregate: {'rmse': 3055.653391462601, 'mae': 2079.37552849157, 'r2': 0.9611223900209676, 'mape': np.float64(5.408347088512779), 'wmape': np.float64(5.0745936580389985)}
2025-07-16 02:21:19 [INFO] pipeline - catboost granular: {'rmse': 7.164140513308316, 'mae': 3.112634275381672, 'r2': 0.9690257606836886, 'mape': np.float64(23.126169274792915), 'wmape': np.float64(20.377603727054627)}
2025-07-16 02:21:19 [INFO] pipeline - catboost aggregate: {'rmse': 3427.202005221296, 'mae': 2483.45320755273, 'r2': 0.9510930268266098, 'mape': np.float64(6.418479237027613), 'wmape': np.float64(6.060721463922327)}
2025-07-16 02:44:15 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE AVALIAÇÃO ====
2025-07-16 02:44:15 [INFO] pipeline - ==== INÍCIO DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-16 02:44:15 [INFO] pipeline - ==== CARREGANDO DADOS PARA AVALIAÇÃO ====
2025-07-16 02:44:15 [INFO] pipeline - Lido data/processed/vendas_processed.csv/part-00000-5b0157c9-3230-417a-8d86-a7676a55ce7c-c000.csv: 230704 linhas, 4 colunas
2025-07-16 02:44:15 [INFO] pipeline - Lido data/models/ml_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 02:44:15 [INFO] pipeline - Lido data/models/catboost_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 02:44:15 [INFO] pipeline - Lido data/models/reconciled_sku_forecast.csv: 270576 linhas, 6 colunas
2025-07-16 02:44:15 [INFO] pipeline - lgbm granular: {'rmse': 8.052946504521012, 'mae': 2.9464274121803675, 'r2': 0.9608634906875356, 'mape': np.float64(15.040836894894902), 'wmape': np.float64(19.28949079910145)}
2025-07-16 02:44:15 [INFO] pipeline - lgbm aggregate: {'rmse': 3055.653391462601, 'mae': 2079.37552849157, 'r2': 0.9611223900209676, 'mape': np.float64(5.408347088512779), 'wmape': np.float64(5.0745936580389985)}
2025-07-16 02:44:15 [INFO] pipeline - catboost granular: {'rmse': 7.164140513308316, 'mae': 3.112634275381672, 'r2': 0.9690257606836886, 'mape': np.float64(23.126169274792915), 'wmape': np.float64(20.377603727054627)}
2025-07-16 02:44:15 [INFO] pipeline - catboost aggregate: {'rmse': 3427.202005221296, 'mae': 2483.45320755273, 'r2': 0.9510930268266098, 'mape': np.float64(6.418479237027613), 'wmape': np.float64(6.060721463922327)}
2025-07-16 02:49:32 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE AVALIAÇÃO ====
2025-07-16 02:49:32 [INFO] pipeline - ==== INÍCIO DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-16 02:49:32 [INFO] pipeline - ==== CARREGANDO DADOS PARA AVALIAÇÃO ====
2025-07-16 02:49:33 [INFO] pipeline - Lido data/processed/vendas_processed.csv/part-00000-5b0157c9-3230-417a-8d86-a7676a55ce7c-c000.csv: 230704 linhas, 4 colunas
2025-07-16 02:49:33 [INFO] pipeline - Lido data/models/ml_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 02:49:33 [INFO] pipeline - Lido data/models/catboost_forecast.csv: 270576 linhas, 3 colunas
2025-07-16 02:49:33 [INFO] pipeline - Lido data/models/reconciled_sku_forecast.csv: 270576 linhas, 6 colunas
2025-07-16 02:49:33 [INFO] pipeline - lgbm granular: {'rmse': 8.052946504521012, 'mae': 2.9464274121803675, 'r2': 0.9608634906875356, 'mape': np.float64(15.040836894894902), 'wmape': np.float64(19.28949079910145)}
2025-07-16 02:49:33 [INFO] pipeline - lgbm aggregate: {'rmse': 3055.653391462601, 'mae': 2079.37552849157, 'r2': 0.9611223900209676, 'mape': np.float64(5.408347088512779), 'wmape': np.float64(5.0745936580389985)}
2025-07-16 02:49:33 [INFO] pipeline - catboost granular: {'rmse': 7.164140513308316, 'mae': 3.112634275381672, 'r2': 0.9690257606836886, 'mape': np.float64(23.126169274792915), 'wmape': np.float64(20.377603727054627)}
2025-07-16 02:49:33 [INFO] pipeline - catboost aggregate: {'rmse': 3427.202005221296, 'mae': 2483.45320755273, 'r2': 0.9510930268266098, 'mape': np.float64(6.418479237027613), 'wmape': np.float64(6.060721463922327)}
2025-07-16 02:49:33 [INFO] pipeline - reconciled granular: {'rmse': 7.297968470278285, 'mae': 2.999701068155815, 'r2': 0.9678577389147373, 'mape': np.float64(18.608370834478745), 'wmape': np.float64(19.638259512196083)}
2025-07-16 02:49:33 [INFO] pipeline - reconciled aggregate: {'rmse': 3198.0918463223325, 'mae': 2264.7736875814744, 'r2': 0.957413373071537, 'mape': np.float64(5.864329280294715), 'wmape': np.float64(5.527046959253055)}
2025-07-16 02:49:33 [INFO] pipeline - Metrics report salvo em data/models/metrics_report.csv
2025-07-16 02:49:33 [INFO] pipeline - ==== FIM DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-16 02:50:13 [INFO] pipeline - ==== INÍCIO FORECAST SKU=123 ====
2025-07-16 02:50:13 [INFO] pipeline - Carregando LGBM de data/models/lgbm_model.pkl
2025-07-16 02:50:13 [INFO] pipeline - Carregando CatBoost de data/models/catboost_model.cbm
2025-07-16 02:50:13 [INFO] pipeline - Histórico SKU=123: 86 linhas (arquivo: data/processed/vendas_processed.csv/part-00000-5b0157c9-3230-417a-8d86-a7676a55ce7c-c000.csv)
2025-07-16 02:50:13 [INFO] pipeline - Features SKU=123: 86 linhas (arquivo: data/features/vendas_features.csv/part-00000-32adba8c-be86-4f64-aeed-cea33669a4a5-c000.csv)
2025-07-16 02:50:13 [INFO] pipeline - Gerado forecast SKU=123 com 93 linhas
2025-07-16 02:50:13 [INFO] pipeline - Forecast SKU salvo em data/models/forecast_sku_123.csv
2025-07-16 02:50:13 [INFO] pipeline - ==== FIM FORECAST SKU=123 ====
2025-07-16 04:18:50 [INFO] pipeline - ==== INÍCIO DO TREINO LIGHTGBM ====
2025-07-16 04:19:12 [INFO] pipeline - ==== INÍCIO DO TREINO LIGHTGBM ====
2025-07-16 04:19:12 [INFO] pipeline - Carregando features de data/features/vendas_features.csv
2025-07-16 04:19:13 [INFO] pipeline - Dados carregados: 230704 linhas, 14 colunas
2025-07-16 04:19:13 [INFO] pipeline - fold 1/5 — RMSE: 5.0482, MAE: 2.5093, MAPE: 14.66%, WMAPE: 21.59%, R²: 0.8944
2025-07-16 04:19:14 [INFO] pipeline - fold 2/5 — RMSE: 6.2112, MAE: 3.5017, MAPE: 17.01%, WMAPE: 19.73%, R²: 0.9062
2025-07-16 04:19:16 [INFO] pipeline - fold 3/5 — RMSE: 80.1813, MAE: 7.5134, MAPE: 15.59%, WMAPE: 37.46%, R²: 0.2152
2025-07-16 04:19:17 [INFO] pipeline - fold 4/5 — RMSE: 4.9465, MAE: 2.4113, MAPE: 14.83%, WMAPE: 21.47%, R²: 0.9025
2025-07-16 04:19:18 [INFO] pipeline - fold 5/5 — RMSE: 4.8540, MAE: 2.5403, MAPE: 15.32%, WMAPE: 21.36%, R²: 0.8858
2025-07-16 04:19:18 [INFO] pipeline - CV RMSE média: 20.2483  desvio: 33.5081
2025-07-16 04:19:18 [INFO] pipeline - Treinando LightGBM no dataset completo
2025-07-16 04:19:20 [INFO] pipeline - Modelo salvo em data/models/lgbm_model.pkl
2025-07-16 04:19:26 [INFO] pipeline - Forecast criado para 7 dias
2025-07-16 04:19:27 [INFO] pipeline - Forecast completo (in-sample + futuro) salvo em data/models/ml_forecast.csv
2025-07-16 04:19:27 [INFO] pipeline - ==== FIM DO TREINO LIGHTGBM ====
2025-07-16 04:21:52 [INFO] pipeline - ==== INÍCIO DO TREINO LIGHTGBM ====
2025-07-16 04:21:52 [INFO] pipeline - Carregando features de data/features/vendas_features.csv
2025-07-16 04:21:52 [INFO] pipeline - Dados carregados: 230704 linhas, 14 colunas
2025-07-16 04:21:53 [INFO] pipeline - fold 1/5 — RMSE: 5.0482, MAE: 2.5093, MAPE: 14.66%, WMAPE: 21.59%, R²: 0.8944
2025-07-16 04:21:54 [INFO] pipeline - fold 2/5 — RMSE: 6.2112, MAE: 3.5017, MAPE: 17.01%, WMAPE: 19.73%, R²: 0.9062
2025-07-16 04:21:55 [INFO] pipeline - fold 3/5 — RMSE: 80.1813, MAE: 7.5134, MAPE: 15.59%, WMAPE: 37.46%, R²: 0.2152
2025-07-16 04:21:57 [INFO] pipeline - fold 4/5 — RMSE: 4.9465, MAE: 2.4113, MAPE: 14.83%, WMAPE: 21.47%, R²: 0.9025
2025-07-16 04:21:59 [INFO] pipeline - fold 5/5 — RMSE: 4.8540, MAE: 2.5403, MAPE: 15.32%, WMAPE: 21.36%, R²: 0.8858
2025-07-16 04:21:59 [INFO] pipeline - CV RMSE média: 20.2483  desvio: 33.5081
2025-07-16 04:21:59 [INFO] pipeline - Treinando LightGBM no dataset completo
2025-07-16 04:22:00 [INFO] pipeline - Modelo salvo em data/models/lgbm_model.pkl
2025-07-16 04:36:22 [INFO] pipeline - ==== INÍCIO LIGHTGBM ====
2025-07-16 04:36:22 [INFO] pipeline - Dados carregados: (230704, 14)
2025-07-16 04:36:23 [INFO] pipeline - fold 1 RMSE 5.0482
2025-07-16 04:36:24 [INFO] pipeline - fold 2 RMSE 6.2112
2025-07-16 04:36:25 [INFO] pipeline - fold 3 RMSE 80.1813
2025-07-16 04:36:26 [INFO] pipeline - fold 4 RMSE 4.9465
2025-07-16 04:36:28 [INFO] pipeline - fold 5 RMSE 4.8540
2025-07-16 04:36:28 [INFO] pipeline - CV RMSE média 20.2483
2025-07-16 04:36:29 [INFO] pipeline - Modelo salvo em data/models/lgbm_model.pkl
2025-07-16 04:36:29 [INFO] pipeline - Previsto dia 2024-04-09 para 1358 SKUs
2025-07-16 04:36:29 [INFO] pipeline - Previsto dia 2024-04-10 para 1358 SKUs
2025-07-16 04:36:29 [INFO] pipeline - Previsto dia 2024-04-11 para 1358 SKUs
2025-07-16 04:36:29 [INFO] pipeline - Previsto dia 2024-04-12 para 1358 SKUs
2025-07-16 04:36:29 [INFO] pipeline - Previsto dia 2024-04-13 para 1358 SKUs
2025-07-16 04:36:29 [INFO] pipeline - Previsto dia 2024-04-14 para 1358 SKUs
2025-07-16 04:36:29 [INFO] pipeline - Previsto dia 2024-04-15 para 1358 SKUs
2025-07-16 04:36:30 [INFO] pipeline - Forecast salvo em data/models/ml_forecast.csv
2025-07-16 04:39:12 [INFO] pipeline - ==== INÍCIO LIGHTGBM ====
2025-07-16 04:39:12 [INFO] pipeline - Dados carregados: (230704, 14)
2025-07-16 04:39:13 [INFO] pipeline - fold 1 RMSE 5.0482
2025-07-16 04:39:14 [INFO] pipeline - fold 2 RMSE 6.2112
2025-07-16 04:39:15 [INFO] pipeline - fold 3 RMSE 80.1813
2025-07-16 04:39:16 [INFO] pipeline - fold 4 RMSE 4.9465
2025-07-16 04:39:17 [INFO] pipeline - fold 5 RMSE 4.8540
2025-07-16 04:39:17 [INFO] pipeline - CV RMSE média 20.2483
2025-07-16 04:39:19 [INFO] pipeline - Modelo salvo em data/models/lgbm_model.pkl
2025-07-16 04:39:20 [INFO] pipeline - Previsto dia 2024-04-09 para 1358 SKUs
2025-07-16 04:39:20 [INFO] pipeline - Previsto dia 2024-04-10 para 1358 SKUs
2025-07-16 04:39:20 [INFO] pipeline - Previsto dia 2024-04-11 para 1358 SKUs
2025-07-16 04:39:20 [INFO] pipeline - Previsto dia 2024-04-12 para 1358 SKUs
2025-07-16 04:39:20 [INFO] pipeline - Previsto dia 2024-04-13 para 1358 SKUs
2025-07-16 04:39:20 [INFO] pipeline - Previsto dia 2024-04-14 para 1358 SKUs
2025-07-16 04:39:20 [INFO] pipeline - Previsto dia 2024-04-15 para 1358 SKUs
2025-07-16 04:39:20 [INFO] pipeline - Forecast salvo em data/models/ml_forecast.csv
2025-07-16 04:53:00 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE FEATURE ENGINEERING ====
2025-07-16 04:53:07 [INFO] pipeline - SparkSession com suporte a Delta iniciada para features
2025-07-16 04:53:07 [INFO] pipeline - ==== INÍCIO DA FEATURE ENGINEERING ====
2025-07-16 04:53:07 [INFO] pipeline - Features: lendo Delta de entrada em data/processed/vendas_processed.delta
2025-07-16 04:53:15 [INFO] pipeline - Features: dados brutos carregados (230704 linhas)
2025-07-16 04:53:15 [INFO] pipeline - Features: flag de imputação criado
2025-07-16 04:53:15 [INFO] pipeline - Features: lags [1, 7, 14] criados
2025-07-16 04:53:15 [INFO] pipeline - Features: rolling windows [7, 14, 30] criados
2025-07-16 04:53:15 [INFO] pipeline - Features: variáveis de calendário criadas
2025-07-16 04:53:20 [INFO] pipeline - Features: CSV salvo em data/features/vendas_features.csv
2025-07-16 04:53:25 [INFO] pipeline - Features: Delta salvo em data/features/vendas_features.delta
2025-07-16 04:53:25 [INFO] pipeline - ==== FIM DA FEATURE ENGINEERING ====
2025-07-16 04:53:25 [INFO] pipeline - SparkSession finalizada
2025-07-16 04:53:25 [INFO] py4j.clientserver - Closing down clientserver connection
2025-07-16 05:04:45 [INFO] pipeline - ==== INÍCIO LIGHTGBM ====
2025-07-16 05:04:46 [INFO] pipeline - Dados carregados: (230704, 14)
2025-07-16 05:04:46 [INFO] pipeline - fold 1 RMSE 5.0482
2025-07-16 05:04:47 [INFO] pipeline - fold 2 RMSE 6.2112
2025-07-16 05:04:48 [INFO] pipeline - fold 3 RMSE 80.1813
2025-07-16 05:04:49 [INFO] pipeline - fold 4 RMSE 4.9465
2025-07-16 05:04:51 [INFO] pipeline - fold 5 RMSE 4.8540
2025-07-16 05:04:51 [INFO] pipeline - CV RMSE média 20.2483
2025-07-16 05:04:52 [INFO] pipeline - Modelo salvo em data/models/lgbm_model.pkl
2025-07-16 05:14:08 [INFO] pipeline - ==== INÍCIO LIGHTGBM ====
2025-07-16 05:14:08 [INFO] pipeline - Dados brutos carregados: (230704, 14)
2025-07-16 05:14:10 [INFO] pipeline - Features geradas: (230704, 14)
2025-07-16 05:14:10 [INFO] pipeline - Colunas de feature: ['is_imputed', 'was_imputed', 'lag_1', 'lag_7', 'lag_14', 'roll_mean_7', 'roll_mean_14', 'roll_mean_30', 'weekday', 'is_weekend', 'month']
2025-07-16 05:14:11 [INFO] pipeline - fold 1 RMSE 5.1329
2025-07-16 05:14:12 [INFO] pipeline - fold 2 RMSE 6.2467
2025-07-16 05:14:13 [INFO] pipeline - fold 3 RMSE 79.7516
2025-07-16 05:14:14 [INFO] pipeline - fold 4 RMSE 4.9785
2025-07-16 05:14:15 [INFO] pipeline - fold 5 RMSE 4.8937
2025-07-16 05:14:15 [INFO] pipeline - CV RMSE média 20.2007
2025-07-16 05:14:16 [INFO] pipeline - Modelo salvo em data/models/lgbm_model.pkl
2025-07-16 05:14:19 [INFO] pipeline - Previsto dia 2024-04-09
2025-07-16 05:14:20 [INFO] pipeline - Previsto dia 2024-04-10
2025-07-16 05:14:22 [INFO] pipeline - Previsto dia 2024-04-11
2025-07-16 05:14:24 [INFO] pipeline - Previsto dia 2024-04-12
2025-07-16 05:14:26 [INFO] pipeline - Previsto dia 2024-04-13
2025-07-16 05:14:27 [INFO] pipeline - Previsto dia 2024-04-14
2025-07-16 05:14:29 [INFO] pipeline - Previsto dia 2024-04-15
2025-07-16 05:14:29 [INFO] pipeline - Forecast salvo em data/models/ml_forecast.csv
2025-07-16 05:16:58 [INFO] pipeline - ==== INÍCIO DO TREINO CATBOOST ====
2025-07-16 05:16:58 [INFO] pipeline - Lendo features de data/features/vendas_features.csv
2025-07-16 05:16:59 [INFO] pipeline - Dados carregados: 230704 linhas, 14 colunas (arquivo: data/features/vendas_features.csv/part-00000-e1634668-9cf8-4a9c-98d3-e674c4d5204d-c000.csv)
2025-07-16 05:16:59 [INFO] pipeline - fold 1/5 — RMSE: 5.1635, MAE: 2.6137, MAPE: 21.15%, WMAPE: 22.48%, R²: 0.8896
2025-07-16 05:17:00 [INFO] pipeline - fold 2/5 — RMSE: 6.2760, MAE: 3.5579, MAPE: 19.80%, WMAPE: 20.05%, R²: 0.9042
2025-07-16 05:17:00 [INFO] pipeline - fold 3/5 — RMSE: 80.3538, MAE: 7.6103, MAPE: 19.52%, WMAPE: 37.94%, R²: 0.2118
2025-07-16 05:17:01 [INFO] pipeline - fold 4/5 — RMSE: 5.2489, MAE: 2.6281, MAPE: 27.03%, WMAPE: 23.40%, R²: 0.8903
2025-07-16 05:17:02 [INFO] pipeline - fold 5/5 — RMSE: 5.1353, MAE: 2.7299, MAPE: 24.69%, WMAPE: 22.95%, R²: 0.8722
2025-07-16 05:17:02 [INFO] pipeline - CV RMSE média: 20.4355  desvio: 33.4987
2025-07-16 05:17:02 [INFO] pipeline - cross-validation concluído
2025-07-16 05:17:02 [INFO] pipeline - Treinando CatBoost no dataset completo
2025-07-16 05:17:04 [INFO] pipeline - Modelo salvo em data/models/catboost_model.cbm
2025-07-16 05:17:09 [INFO] pipeline - Forecast CatBoost criado para 7 dias
2025-07-16 05:17:09 [INFO] pipeline - Forecast completo (in-sample + futuro) salvo em data/models/catboost_forecast.csv
2025-07-16 05:17:09 [INFO] pipeline - ==== FIM DO TREINO CATBOOST ====
2025-07-16 05:17:49 [INFO] pipeline - ==== INÍCIO DO TREINO CATBOOST ====
2025-07-16 05:17:49 [INFO] pipeline - Lendo features de data/features/vendas_features.csv
2025-07-16 05:17:49 [INFO] pipeline - Dados carregados: 230704 linhas, 14 colunas (arquivo: data/features/vendas_features.csv/part-00000-e1634668-9cf8-4a9c-98d3-e674c4d5204d-c000.csv)
2025-07-16 05:17:49 [INFO] pipeline - fold 1/5 — RMSE: 5.1635, MAE: 2.6137, MAPE: 21.15%, WMAPE: 22.48%, R²: 0.8896
2025-07-16 05:17:50 [INFO] pipeline - fold 2/5 — RMSE: 6.2760, MAE: 3.5579, MAPE: 19.80%, WMAPE: 20.05%, R²: 0.9042
2025-07-16 05:17:51 [INFO] pipeline - fold 3/5 — RMSE: 80.3538, MAE: 7.6103, MAPE: 19.52%, WMAPE: 37.94%, R²: 0.2118
2025-07-16 05:17:52 [INFO] pipeline - fold 4/5 — RMSE: 5.2489, MAE: 2.6281, MAPE: 27.03%, WMAPE: 23.40%, R²: 0.8903
2025-07-16 05:17:53 [INFO] pipeline - fold 5/5 — RMSE: 5.1353, MAE: 2.7299, MAPE: 24.69%, WMAPE: 22.95%, R²: 0.8722
2025-07-16 05:17:53 [INFO] pipeline - CV RMSE média: 20.4355  desvio: 33.4987
2025-07-16 05:17:53 [INFO] pipeline - cross-validation concluído
2025-07-16 05:17:53 [INFO] pipeline - Treinando CatBoost no dataset completo
2025-07-16 05:17:55 [INFO] pipeline - Modelo salvo em data/models/catboost_model.cbm
2025-07-16 05:18:01 [INFO] pipeline - Forecast CatBoost criado para 7 dias
2025-07-16 05:18:01 [INFO] pipeline - Forecast completo (in-sample + futuro) salvo em data/models/catboost_forecast.csv
2025-07-16 05:18:01 [INFO] pipeline - ==== FIM DO TREINO CATBOOST ====
2025-07-16 05:18:52 [INFO] pipeline - ==== INÍCIO CATBOOST ====
2025-07-16 05:18:52 [INFO] pipeline - Dados brutos carregados: (230704, 14)
2025-07-16 05:18:55 [INFO] pipeline - Features geradas: (230704, 14)
2025-07-16 05:18:55 [INFO] pipeline - Colunas de feature: ['is_imputed', 'was_imputed', 'lag_1', 'lag_7', 'lag_14', 'roll_mean_7', 'roll_mean_14', 'roll_mean_30', 'weekday', 'is_weekend', 'month']
2025-07-16 05:18:55 [INFO] pipeline - fold 1 RMSE 5.2134
2025-07-16 05:18:56 [INFO] pipeline - fold 2 RMSE 6.3197
2025-07-16 05:18:57 [INFO] pipeline - fold 3 RMSE 80.1870
2025-07-16 05:18:58 [INFO] pipeline - fold 4 RMSE 5.3907
2025-07-16 05:18:59 [INFO] pipeline - fold 5 RMSE 5.2189
2025-07-16 05:18:59 [INFO] pipeline - CV RMSE média 20.4659
2025-07-16 05:19:01 [INFO] pipeline - Modelo salvo em data/models/catboost_model.cbm
2025-07-16 05:19:03 [INFO] pipeline - Previsto dia 2024-04-09
2025-07-16 05:19:05 [INFO] pipeline - Previsto dia 2024-04-10
2025-07-16 05:19:07 [INFO] pipeline - Previsto dia 2024-04-11
2025-07-16 05:19:09 [INFO] pipeline - Previsto dia 2024-04-12
2025-07-16 05:19:10 [INFO] pipeline - Previsto dia 2024-04-13
2025-07-16 05:19:12 [INFO] pipeline - Previsto dia 2024-04-14
2025-07-16 05:19:14 [INFO] pipeline - Previsto dia 2024-04-15
2025-07-16 05:19:15 [INFO] pipeline - Forecast salvo em data/models/catboost_forecast.csv
2025-07-16 05:19:58 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE RECONCILIAÇÃO ====
2025-07-16 05:19:58 [INFO] pipeline - ==== INÍCIO DA RECONCILIAÇÃO ====
2025-07-16 05:19:58 [INFO] pipeline - Lendo forecast LightGBM de data/models/ml_forecast.csv
2025-07-16 05:19:58 [INFO] pipeline - ML forecast: 240210 linhas
2025-07-16 05:19:58 [INFO] pipeline - Lendo forecast CatBoost de data/models/catboost_forecast.csv
2025-07-16 05:19:58 [INFO] pipeline - CatBoost forecast: 240210 linhas
2025-07-16 05:19:58 [INFO] pipeline - Lendo histórico processado de data/processed/vendas_processed.csv
2025-07-16 05:19:58 [INFO] pipeline - Histórico: 230704 linhas (arquivo: data/processed/vendas_processed.csv/part-00000-5b0157c9-3230-417a-8d86-a7676a55ce7c-c000.csv)
2025-07-16 05:19:58 [INFO] pipeline - Criado campo 'reconciled' = média de lgbm_pred e cb_pred
2025-07-16 05:19:58 [INFO] pipeline - Computado resumo diário agregado
2025-07-16 05:19:59 [INFO] pipeline - Reconciled SKU-level salvo em data/models/reconciled_sku_forecast.csv
2025-07-16 05:19:59 [INFO] pipeline - Reconciled daily summary salvo em data/models/reconciled_daily_summary.csv
2025-07-16 05:19:59 [INFO] pipeline - ==== FIM DA RECONCILIAÇÃO ====
2025-07-16 05:20:06 [INFO] pipeline - ==== CONFIGURAÇÃO DE LOG DE AVALIAÇÃO ====
2025-07-16 05:20:06 [INFO] pipeline - ==== INÍCIO DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-16 05:20:06 [INFO] pipeline - ==== CARREGANDO DADOS PARA AVALIAÇÃO ====
2025-07-16 05:20:06 [INFO] pipeline - Lido data/processed/vendas_processed.csv/part-00000-5b0157c9-3230-417a-8d86-a7676a55ce7c-c000.csv: 230704 linhas, 4 colunas
2025-07-16 05:20:06 [INFO] pipeline - Lido data/models/ml_forecast.csv: 240210 linhas, 3 colunas
2025-07-16 05:20:06 [INFO] pipeline - Lido data/models/catboost_forecast.csv: 240210 linhas, 3 colunas
2025-07-16 05:20:06 [INFO] pipeline - Lido data/models/reconciled_sku_forecast.csv: 240210 linhas, 6 colunas
2025-07-16 05:20:06 [INFO] pipeline - lgbm granular: {'rmse': 7.811415691738551, 'mae': 2.9708396018641117, 'r2': 0.9631759154876885, 'mape': np.float64(16.213734197184998), 'wmape': np.float64(19.449311029643642)}
2025-07-16 05:20:06 [INFO] pipeline - lgbm aggregate: {'rmse': 3050.288541138267, 'mae': 2110.394269946974, 'r2': 0.9612587860286518, 'mape': np.float64(5.471137207253645), 'wmape': np.float64(5.150293071883756)}
2025-07-16 05:20:06 [INFO] pipeline - catboost granular: {'rmse': 7.26416873984058, 'mae': 3.1833172156499354, 'r2': 0.9681547760956566, 'mape': np.float64(26.59869150105079), 'wmape': np.float64(20.840346477926992)}
2025-07-16 05:20:06 [INFO] pipeline - catboost aggregate: {'rmse': 3444.4884227871694, 'mae': 2482.9131297057074, 'r2': 0.9505984201613915, 'mape': np.float64(6.431938659256674), 'wmape': np.float64(6.059403435706743)}
2025-07-16 05:20:06 [INFO] pipeline - reconciled granular: {'rmse': 7.299259760204431, 'mae': 3.042721228576602, 'r2': 0.9678463635162216, 'mape': np.float64(20.517589540207407), 'wmape': np.float64(19.91990126762577)}
2025-07-16 05:20:06 [INFO] pipeline - reconciled aggregate: {'rmse': 3221.5631630415396, 'mae': 2281.461934426957, 'r2': 0.9567859788383013, 'mape': np.float64(5.905939264575375), 'wmape': np.float64(5.567773643993501)}
2025-07-16 05:20:06 [INFO] pipeline - Metrics report salvo em data/models/metrics_report.csv
2025-07-16 05:20:06 [INFO] pipeline - ==== FIM DA AVALIAÇÃO DE MÉTRICAS ====
2025-07-16 05:20:20 [INFO] pipeline - ==== INÍCIO FORECAST SKU=1 ====
2025-07-16 05:20:20 [INFO] pipeline - Carregando LGBM de data/models/lgbm_model.pkl
2025-07-16 05:20:20 [INFO] pipeline - Carregando CatBoost de data/models/catboost_model.cbm
2025-07-16 05:20:20 [INFO] pipeline - Histórico SKU=1: 84 linhas (arquivo: data/processed/vendas_processed.csv/part-00000-5b0157c9-3230-417a-8d86-a7676a55ce7c-c000.csv)
2025-07-16 05:20:20 [INFO] pipeline - Features SKU=1: 84 linhas (arquivo: data/features/vendas_features.csv/part-00000-e1634668-9cf8-4a9c-98d3-e674c4d5204d-c000.csv)
2025-07-16 05:20:20 [INFO] pipeline - Gerado forecast SKU=1 com 91 linhas
2025-07-16 05:20:20 [INFO] pipeline - Forecast SKU salvo em data/models/forecast_sku_1.csv
2025-07-16 05:20:20 [INFO] pipeline - ==== FIM FORECAST SKU=1 ====
